import os
import time
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
import config
import utils

# é‡è©¦è£é£¾å™¨ï¼šé‡å°ç¶²è·¯éŒ¯èª¤é€²è¡ŒæŒ‡æ•¸é€€é¿é‡è©¦
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type(requests.RequestException)
)
def fetch_url(url):
    """
    ç™¼é€ GET è«‹æ±‚ä¸¦åŒ…å«éŒ¯èª¤é‡è©¦æ©Ÿåˆ¶
    """
    response = requests.get(url, headers=config.HEADERS, timeout=10)
    response.raise_for_status()
    return response

def get_fund_data():
    """
    æŠ“å–ç›®æ¨™åŸºé‡‘çš„æœ€æ–°æ·¨å€¼èˆ‡æ—¥æœŸ
    """
    print(f'æ­£åœ¨æŠ“å–åŸºé‡‘ {config.TARGET_FUND["name"]} çš„æœ€æ–°æ·¨å€¼...')
    try:
        res = fetch_url(config.TARGET_FUND['url'])
        soup = BeautifulSoup(res.content, 'html.parser')
        
        # æ ¹æ“š climb-warm.ipynb çš„é‚è¼¯å®šä½æ—¥æœŸèˆ‡æ·¨å€¼
        date_tag = soup.select('.ywm_fi_sec')
        if len(date_tag) < 3:
            print("âš ï¸ ç„¡æ³•å®šä½åŸºé‡‘æ—¥æœŸæ¨™ç±¤")
            return None
            
        date_text = date_tag[2].text.strip() # æ ¼å¼é€šå¸¸ç‚º YYYY/MM/DD
        
        data_tag = soup.select('.ywm_fi_cell')
        price_element = data_tag[1].find('h4', {'class': 'red'})
        if not price_element:
            print("âš ï¸ ç„¡æ³•å®šä½åŸºé‡‘æ·¨å€¼æ¨™ç±¤")
            return None
            
        price_text = price_element.text.strip().replace('TWD', '').replace(',', '').strip()
        price = float(price_text)
        
        print(f'åŸºé‡‘æŠ“å–æˆåŠŸ: {date_text}, æ·¨å€¼: {price}')
        return {'date': date_text, 'net_value': price}
    except Exception as e:
        print(f"åŸºé‡‘æŠ“å–å¤±æ•—: {e}")
        return None

def save_fund_data(data):
    """
    å„²å­˜åŸºé‡‘è³‡æ–™
    """
    if not data:
        return
    
    utils.ensure_dir_exists(config.FUND_DATA_DIR)
    file_path = os.path.join(config.FUND_DATA_DIR, f"{config.TARGET_FUND['id']}.csv")
    
    df = pd.DataFrame([data])
    mode = 'a' if os.path.exists(file_path) else 'w'
    header = not os.path.exists(file_path)
    
    if mode == 'a':
        existing = pd.read_csv(file_path)
        if data['date'] in existing['date'].values:
            print('â„¹ï¸ åŸºé‡‘è³‡æ–™å·²å­˜åœ¨ï¼Œä¸é‡è¤‡å¯«å…¥')
            return
            
    df.to_csv(file_path, mode=mode, header=header, index=False)
    print('ğŸ’¾ åŸºé‡‘è³‡æ–™å¯«å…¥å®Œæˆï¼')

def get_stock_data(date_str, stock_code):
    """
    æŠ“å–è­‰äº¤æ‰€å€‹è‚¡æ—¥æˆäº¤è³‡è¨Š
    
    åƒæ•¸:
        date_str (str): æ—¥æœŸå­—ä¸²ï¼Œæ ¼å¼ç‚º YYYYMM01
        stock_code (str): è‚¡ç¥¨ä»£ç¢¼
        
    å›å‚³:
        pd.DataFrame: åŒ…å«è©²æœˆä»½æˆäº¤è³‡è¨Šçš„ DataFrameï¼Œè‹¥ç„¡è³‡æ–™å‰‡å›å‚³ None
    """
    print(f'æ­£åœ¨æŠ“å– {stock_code} æ–¼ {date_str} çš„è³‡æ–™...')
    
    # æ ¼å¼åŒ–ç›®æ¨™ç¶²å€
    url = config.BASE_URL_PATTERN.format(date_str, stock_code)
    
    try:
        res = fetch_url(url)
        soup = BeautifulSoup(res.content, 'html.parser')
        
        # å°‹æ‰¾è¡¨æ ¼æ¨™é¡Œèˆ‡å…§å®¹
        thead = soup.find('thead')
        if thead is None:
            print(f"è­¦å‘Š: ç„¡æ³•æ‰¾åˆ°è¡¨æ ¼æ¨™é¡Œ (å¯èƒ½è©²æœˆç„¡è³‡æ–™æˆ–ä¼‘å¸‚) - {stock_code} {date_str}")
            return None
        
        title_rows = thead.find_all('tr')
        if not title_rows:
            return None
            
        # è­‰äº¤æ‰€çš„è¡¨æ ¼å¯èƒ½æœ‰å…©å±¤ trï¼Œæˆ‘å€‘å–æœ€å¾Œä¸€å±¤åŒ…å«å¯¦éš›æ¬„ä½åç¨±çš„
        columns = [th.text.strip() for th in title_rows[-1].find_all(['th', 'td'])]
        
        # æª¢æŸ¥æ¬„ä½æ•¸é‡æ˜¯å¦èˆ‡è³‡æ–™å°é½Š
        datalist = []
        tbody = soup.find('tbody')
        if tbody:
             for row in tbody.find_all('tr'):
                cols = [col.text.strip() for col in row.find_all('td')]
                if len(cols) == len(columns):
                    datalist.append(cols)
        
        if not datalist:
            return None

        # å»ºç«‹ DataFrame
        df = pd.DataFrame(datalist, columns=columns)
        
        # è½‰æ›æ—¥æœŸæ ¼å¼ (ä½¿ç”¨ utils æ¨¡çµ„)
        if 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = df['æ—¥æœŸ'].apply(utils.transform_date)
            
        print(f'è‚¡ç¥¨ {stock_code} {config.WATCH_STOCKS.get(stock_code, "")} {date_str} è³‡æ–™æœé›†æˆåŠŸ')
        return df
        
    except Exception as e:
        print(f"æŠ“å–å¤±æ•— {stock_code} {date_str}: {e}")
        return None

        
        title_row = thead.find('tr')
        if title_row is None:
            return None
            
        # ä¿®æ­£ï¼šæ¨™é¡Œåˆ—é€šå¸¸ä½¿ç”¨ <th> æ¨™ç±¤ï¼Œè€Œé <td>
        columns = [th.text.strip() for th in title_row.find_all(['th', 'td'])]
        
        datalist = []
        tbody = soup.find('tbody')
        if tbody:
             for row in tbody.find_all('tr'):
                datalist.append([col.text.strip() for col in row.find_all('td')])
        
        if not datalist:
            return None

        # å»ºç«‹ DataFrame
        df = pd.DataFrame(datalist, columns=columns)
        
        # è½‰æ›æ—¥æœŸæ ¼å¼ (ä½¿ç”¨ utils æ¨¡çµ„)
        if 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = df['æ—¥æœŸ'].apply(utils.transform_date)
            
        print(f'âœ… {stock_code} {config.WATCH_STOCKS.get(stock_code, "")} {date_str} è³‡æ–™æœé›†æˆåŠŸ')
        return df
        
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±æ•— {stock_code} {date_str}: {e}")
        return None

def save_stock_data(df, stock_code):
    """
    å°‡è‚¡ç¥¨ DataFrame å„²å­˜ç‚º CSV æª”æ¡ˆ
    """
    if df is None or df.empty:
        return

    utils.ensure_dir_exists(config.STOCK_DATA_DIR)
    
    file_name = f"{stock_code}{config.WATCH_STOCKS.get(stock_code, '')}.csv"
    file_path = os.path.join(config.STOCK_DATA_DIR, file_name)
    
    mode = 'a' if os.path.exists(file_path) else 'w'
    header = not os.path.exists(file_path)
    
    try:
        if mode == 'a':
            existing_data = pd.read_csv(file_path)
            if not df.empty and df['æ—¥æœŸ'].iloc[0] in existing_data['æ—¥æœŸ'].values:
                print(f'â„¹ï¸ {stock_code} è³‡æ–™å·²é‡è¤‡ï¼Œè·³éå¯«å…¥')
                return

        df.to_csv(file_path, mode=mode, header=header, index=False)
        print(f'ğŸ’¾ {stock_code} å¯«å…¥å®Œæˆï¼')
        
    except Exception as e:
        print(f"âŒ è‚¡ç¥¨å­˜æª”éŒ¯èª¤: {e}")

def main():
    # 1. æŠ“å–è§€å¯Ÿæ¨™çš„è‚¡ç¥¨è³‡æ–™
    today = datetime.today()
    target_dates = utils.generate_date_list(2023, 1, today.year, today.month)
    watch_stocks = list(config.WATCH_STOCKS.keys())
    
    print(f"é–‹å§‹çˆ¬å–è‚¡ç¥¨è³‡æ–™...")
    for stock in watch_stocks:
        for date_str in target_dates:
            df = get_stock_data(date_str, stock)
            save_stock_data(df, stock)
            time.sleep(3) 

    # 2. æŠ“å–ç›®æ¨™åŸºé‡‘è³‡æ–™
    fund_data = get_fund_data()
    save_fund_data(fund_data)


if __name__ == "__main__":
    main()