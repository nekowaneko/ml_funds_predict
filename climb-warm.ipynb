{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下載網頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T15:18:02.901259Z",
     "iopub.status.busy": "2023-09-13T15:18:02.900477Z",
     "iopub.status.idle": "2023-09-13T15:18:04.155895Z",
     "shell.execute_reply": "2023-09-13T15:18:04.154907Z",
     "shell.execute_reply.started": "2023-09-13T15:18:02.901210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nif htmlfile.status_code == requests.codes.ok:\\n    print('取得網頁內容成功')\\n    print('網頁內容大小=',len(htmlfile.text))\\nelse:\\n    print('取得網頁內容失敗')\\nprint(htmlfile.text)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://wealth.yuanta.com.tw/WMECPortal/Wealth/Fundcenter/FundPage/60021903?'\n",
    "htmlfile = requests.get(url)\n",
    "print(type(htmlfile))\n",
    "\n",
    "'''\n",
    "if htmlfile.status_code == requests.codes.ok:\n",
    "    print('取得網頁內容成功')\n",
    "    print('網頁內容大小=',len(htmlfile.text))\n",
    "else:\n",
    "    print('取得網頁內容失敗')\n",
    "print(htmlfile.text)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **儲存下載的網頁**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T07:12:35.104063Z",
     "iopub.status.busy": "2023-09-15T07:12:35.103624Z",
     "iopub.status.idle": "2023-09-15T07:12:37.019220Z",
     "shell.execute_reply": "2023-09-15T07:12:37.017990Z",
     "shell.execute_reply.started": "2023-09-15T07:12:35.104029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下載成功\n",
      "40960\n",
      "4508\n",
      "以uni_hor.html儲存網頁HTML檔案成功\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://wealth.yuanta.com.tw/WMECPortal/Wealth/Fundcenter/FundPage/60021903?'\n",
    "\n",
    "try:\n",
    "    htmlfile = requests.get(url)\n",
    "    print('下載成功')\n",
    "except Exception as err:\n",
    "    print('下載網頁失敗:%s'% err)\n",
    "    \n",
    "fn = 'uni_hor.html'\n",
    "with open(fn,'wb') as file_obj:\n",
    "    for diskStorage in htmlfile.iter_content(40960):\n",
    "        size=file_obj.write(diskStorage)\n",
    "        print(size)\n",
    "    print('以%s儲存網頁HTML檔案成功'%fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T06:48:58.137346Z",
     "iopub.status.busy": "2023-09-14T06:48:58.136855Z",
     "iopub.status.idle": "2023-09-14T06:48:59.554702Z",
     "shell.execute_reply": "2023-09-14T06:48:59.553650Z",
     "shell.execute_reply.started": "2023-09-14T06:48:58.137311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "版本: 11\n",
      "網址: https://www.ntnu.edu.tw/\n",
      "下載狀況: 200\n",
      "headers:\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "#https://www.ntnu.edu.tw/\n",
    "#https://wealth.yuanta.com.tw/WMECPortal/Wealth/Fundcenter/FundPage/60021903?\n",
    "\n",
    "url = 'https://www.ntnu.edu.tw/'\n",
    "htmlfile = urllib.request.urlopen(url)\n",
    "#print(htmlfile.read().decode('utf-8'))   #將二進位顯示為中文\n",
    "print('版本:',htmlfile.version)\n",
    "print('網址:',htmlfile.geturl())\n",
    "print('下載狀況:',htmlfile.status)\n",
    "print('headers:')\n",
    "#for header in htmlfile.getheaders():\n",
    "    #print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 偽裝成瀏覽器擷取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T08:06:57.323574Z",
     "iopub.status.busy": "2024-07-05T08:06:57.323186Z",
     "iopub.status.idle": "2024-07-05T08:06:57.745191Z",
     "shell.execute_reply": "2024-07-05T08:06:57.743911Z",
     "shell.execute_reply.started": "2024-07-05T08:06:57.323544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "偽裝成功\n"
     ]
    }
   ],
   "source": [
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "url = 'http://aaa.24ht.com.tw/style=\"color:rgb(175,0,0)\">'\n",
    "#req=urllib.request.Request(url,headers=headers)\n",
    "htmlfile = requests.get(url, headers=headers)\n",
    "htmlfile.encoding = 'utf-8'\n",
    "htmlfile.raise_for_status()\n",
    "print('偽裝成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T06:59:21.194742Z",
     "iopub.status.busy": "2023-09-14T06:59:21.193449Z",
     "iopub.status.idle": "2023-09-14T06:59:21.588430Z",
     "shell.execute_reply": "2023-09-14T06:59:21.587201Z",
     "shell.execute_reply.started": "2023-09-14T06:59:21.194690Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.httpbin.org/image/jpeg'\n",
    "r = requests.get(url)\n",
    "image=r.content\n",
    "\n",
    "fn = 'out3_38.jpg'\n",
    "with open(fn,'wb') as fout:\n",
    "    fout.write(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設置代理IP\n",
    "使用免費IP www.xiladaili.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T07:08:54.364785Z",
     "iopub.status.busy": "2023-09-14T07:08:54.364315Z",
     "iopub.status.idle": "2023-09-14T07:08:54.459630Z",
     "shell.execute_reply": "2023-09-14T07:08:54.458423Z",
     "shell.execute_reply.started": "2023-09-14T07:08:54.364748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代理IP使用成功\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "proxies = {\"http\":'http://203.83.182.86:8000'}  #ip:port\n",
    "\n",
    "r=requests.get('https://docs.python.org',proxies=proxies)\n",
    "if r.status_code == 200:\n",
    "    print('代理IP使用成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **匯入網頁表格資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T07:15:19.012873Z",
     "iopub.status.busy": "2023-09-14T07:15:19.012117Z",
     "iopub.status.idle": "2023-09-14T07:15:19.303207Z",
     "shell.execute_reply": "2023-09-14T07:15:19.301806Z",
     "shell.execute_reply.started": "2023-09-14T07:15:19.012837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元素: 0\n",
      "                                                   0\n",
      "0  (adsbygoogle = window.adsbygoogle || []).push(...\n",
      "\n",
      "元素: 1\n",
      "                                                   0\n",
      "0  (adsbygoogle = window.adsbygoogle || []).push(...\n",
      "1  首頁 市場動態 歷史股價 基金淨值 基金分類 經濟數據 公債利率指數 公債ETF  指數期貨...\n",
      "\n",
      "元素: 2\n",
      "    0                                                  1\n",
      "0 NaN  (adsbygoogle = window.adsbygoogle || []).push(...\n",
      "\n",
      "元素: 3\n",
      "                                                   0                   1\n",
      "0  首頁 市場動態 歷史股價 基金淨值 基金分類 經濟數據 公債利率指數 公債ETF  指數期貨...  2023/9/14 15:15:19\n",
      "\n",
      "元素: 4\n",
      "                                                   0  \\\n",
      "0  市場動態 全球股市排行榜 相對低檔股市指數 相對高檔股市指數 國際指數期貨 股市指數歷史資料...   \n",
      "\n",
      "                                                   1  \n",
      "0  全球貨幣匯率 2023/9/14 23:15:19  全球匯率 (Currency Exch...  \n",
      "\n",
      "元素: 5\n",
      "                                                   0\n",
      "0  市場動態 全球股市排行榜 相對低檔股市指數 相對高檔股市指數 國際指數期貨 股市指數歷史資料...\n",
      "\n",
      "元素: 6\n",
      "                                                   0\n",
      "0  ETF 台灣ETF列表 指數ETF 正2反1 ETF AI科技 ETF 電動車ETF 高股息...\n",
      "\n",
      "元素: 7\n",
      "                                               0\n",
      "0  債券ETF 美國政府公債ETF 投資級公司債ETF 非投資級債券ETF 新興市場債券ETF\n",
      "\n",
      "元素: 8\n",
      "                           0   1\n",
      "0  全球貨幣匯率 2023/9/14 23:15:19 NaN\n",
      "\n",
      "元素: 9\n",
      "                           0                         1  \\\n",
      "0   全球匯率 (Currency Exchange)  全球匯率 (Currency Exchange)   \n",
      "1                         貨幣                        匯率   \n",
      "2                      歐元/美元                    1.0739   \n",
      "3                      英鎊/美元                    1.2489   \n",
      "4                    美元/瑞士法郎                    0.8927   \n",
      "5                    美元/瑞典克朗                   11.1104   \n",
      "6                   美元/俄羅斯盧布                   96.2596   \n",
      "7                    美元/烏克蘭幣                   36.6422   \n",
      "8                    美元/匈牙利幣                    357.21   \n",
      "9                    美元/土耳其幣                   26.9066   \n",
      "10                    美元/南非幣                   18.7900   \n",
      "11                   美元/以色列幣                    3.8133   \n",
      "12                    美元/摩洛哥                    9.8442   \n",
      "13                     澳幣/美元                    0.6433   \n",
      "14                     紐幣/美元                    0.5931   \n",
      "15                     美元/日圓                    147.12   \n",
      "16                    美元/人民幣                    7.2744   \n",
      "17                     美元/港幣                    7.8251   \n",
      "18                     美元/台幣                    31.904   \n",
      "19                     美元/韓圜                   1324.74   \n",
      "20                     美元/泰銖                    35.735   \n",
      "21                     美元/新元                    1.3599   \n",
      "22                    美元/菲披索                    56.715   \n",
      "23                    美元/馬來幣                    4.6790   \n",
      "24                    美元/印尼盾                   15354.4   \n",
      "25                   美元/印度盧比                    82.979   \n",
      "26                     美元/加幣                    1.3539   \n",
      "27                    美元/巴西幣                    4.9158   \n",
      "28                  美元/墨西哥披索                   17.1250   \n",
      "29                    美元/阿根廷                  349.9700   \n",
      "30                     美元/智利                    879.90   \n",
      "\n",
      "                           2                         3  \\\n",
      "0   全球匯率 (Currency Exchange)  全球匯率 (Currency Exchange)   \n",
      "1                         漲跌                        比例   \n",
      "2                     0.0013                     0.12%   \n",
      "3                     0.0003                     0.02%   \n",
      "4                    -0.0008                    -0.09%   \n",
      "5                    -0.0130                    -0.12%   \n",
      "6                     0.0346                     0.04%   \n",
      "7                    -0.0203                    -0.06%   \n",
      "8                      -0.43                    -0.12%   \n",
      "9                     0.0326                     0.12%   \n",
      "10                   -0.0095                    -0.05%   \n",
      "11                   -0.0046                    -0.12%   \n",
      "12                   -0.0053                    -0.05%   \n",
      "13                    0.0014                     0.22%   \n",
      "14                    0.0014                     0.24%   \n",
      "15                     -0.32                    -0.21%   \n",
      "16                    0.0044                     0.06%   \n",
      "17                   -0.0006                    -0.01%   \n",
      "18                    -0.033                    -0.10%   \n",
      "19                     -2.68                    -0.20%   \n",
      "20                     0.022                     0.06%   \n",
      "21                   -0.0008                    -0.06%   \n",
      "22                     0.055                     0.10%   \n",
      "23                    0.0015                     0.03%   \n",
      "24                      10.6                     0.07%   \n",
      "25                    -0.021                    -0.03%   \n",
      "26                   -0.0005                    -0.04%   \n",
      "27                    0.0010                     0.02%   \n",
      "28                   -0.0165                    -0.10%   \n",
      "29                   -0.0522                    -0.01%   \n",
      "30                    -11.60                    -1.30%   \n",
      "\n",
      "                           4  \n",
      "0   全球匯率 (Currency Exchange)  \n",
      "1                         台北  \n",
      "2                      15:06  \n",
      "3                      15:07  \n",
      "4                      15:06  \n",
      "5                      15:06  \n",
      "6                      15:07  \n",
      "7                      15:07  \n",
      "8                      15:06  \n",
      "9                      15:06  \n",
      "10                     15:06  \n",
      "11                     15:06  \n",
      "12                     15:06  \n",
      "13                     15:06  \n",
      "14                     15:07  \n",
      "15                     15:06  \n",
      "16                     15:07  \n",
      "17                     15:06  \n",
      "18                     15:05  \n",
      "19                     15:06  \n",
      "20                     15:06  \n",
      "21                     15:06  \n",
      "22                     15:06  \n",
      "23                     15:05  \n",
      "24                     15:06  \n",
      "25                     15:06  \n",
      "26                     15:07  \n",
      "27                     09/13  \n",
      "28                     15:06  \n",
      "29                     15:06  \n",
      "30                     15:00  \n",
      "\n",
      "元素: 10\n",
      "                                                   0\n",
      "0  (adsbygoogle = window.adsbygoogle || []).push(...\n",
      "\n",
      "元素: 11\n",
      "                                                   0\n",
      "0  統一發票  | 12星座分析  | 行動網站  | Wordle每日答案  | Wordle...\n",
      "1  全球股市指數 / 国际股市指数 / World Indices / Мировые инде...\n",
      "2                         紅漲綠跌  綠漲紅跌  回復預設(刪除cookie)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.stockq.org/market/currency.php'\n",
    "aa=pd.read_html(url)\n",
    "\n",
    "item=0\n",
    "for a in aa:\n",
    "    print('元素:',item)\n",
    "    print(a)\n",
    "    print()\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T07:23:43.358783Z",
     "iopub.status.busy": "2023-09-14T07:23:43.357873Z",
     "iopub.status.idle": "2023-09-14T07:23:43.542149Z",
     "shell.execute_reply": "2023-09-14T07:23:43.540764Z",
     "shell.execute_reply.started": "2023-09-14T07:23:43.358726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          貨幣        匯率       漲跌      比例     台北\n",
      "2      歐元/美元    1.0741   0.0014   0.14%  14:55\n",
      "3      英鎊/美元    1.2493   0.0006   0.05%  14:55\n",
      "4    美元/瑞士法郎    0.8919  -0.0015  -0.17%  14:55\n",
      "5    美元/瑞典克朗   11.1170  -0.0064  -0.06%  14:56\n",
      "6   美元/俄羅斯盧布   96.5265   0.3015   0.31%  14:55\n",
      "7    美元/烏克蘭幣   36.6422  -0.0203  -0.06%  14:54\n",
      "8    美元/匈牙利幣    357.27    -0.37  -0.10%  14:54\n",
      "9    美元/土耳其幣   26.9467   0.0293   0.11%  14:55\n",
      "10    美元/南非幣   18.7927   0.0006   0.00%  14:56\n",
      "11   美元/以色列幣    3.8159  -0.0022  -0.06%  14:55\n",
      "12    美元/摩洛哥    9.8442  -0.0053  -0.05%  14:54\n",
      "13     澳幣/美元    0.6438   0.0018   0.28%  14:55\n",
      "14     紐幣/美元    0.5933   0.0019   0.31%  14:55\n",
      "15     美元/日圓    147.10    -0.34  -0.23%  14:55\n",
      "16    美元/人民幣    7.2742   0.0044   0.06%  14:55\n",
      "17     美元/港幣    7.8252  -0.0005  -0.01%  14:55\n",
      "18     美元/台幣    31.906   -0.031  -0.10%  14:56\n",
      "19     美元/韓圜   1325.65    -2.63  -0.20%  14:55\n",
      "20     美元/泰銖    35.729    0.016   0.04%  14:54\n",
      "21     美元/新元    1.3596  -0.0010  -0.08%  14:56\n",
      "22    美元/菲披索    56.710    0.049   0.09%  14:54\n",
      "23    美元/馬來幣    4.6790   0.0015   0.03%  14:55\n",
      "24    美元/印尼盾   15353.6      9.9   0.06%  14:54\n",
      "25   美元/印度盧比    82.969   -0.031  -0.04%  14:55\n",
      "26     美元/加幣    1.3535  -0.0009  -0.07%  14:55\n",
      "27    美元/巴西幣    4.9158   0.0010   0.02%  09/13\n",
      "28  美元/墨西哥披索   17.1257  -0.0160  -0.09%  14:55\n",
      "29    美元/阿根廷  349.9700  -0.0522  -0.01%  14:54\n",
      "30     美元/智利    879.90   -11.60  -1.30%  14:30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.stockq.org/market/currency.php'\n",
    "aa=pd.read_html(url)\n",
    "\n",
    "a=aa[9]\n",
    "a=a.drop(a.index[[0,1]])\n",
    "a.columns=['貨幣','匯率','漲跌','比例','台北']\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T12:19:57.825835Z",
     "iopub.status.busy": "2023-09-20T12:19:57.825471Z",
     "iopub.status.idle": "2023-09-20T12:20:13.722284Z",
     "shell.execute_reply": "2023-09-20T12:20:13.720798Z",
     "shell.execute_reply.started": "2023-09-20T12:19:57.825806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T07:13:49.505939Z",
     "iopub.status.busy": "2023-09-15T07:13:49.505430Z",
     "iopub.status.idle": "2023-09-15T07:13:49.958662Z",
     "shell.execute_reply": "2023-09-15T07:13:49.957678Z",
     "shell.execute_reply.started": "2023-09-15T07:13:49.505882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "url = 'http://www.grandtech.info/'\n",
    "r = requests.get(url)\n",
    "objSoup=bs4.BeautifulSoup(r.text,'lxml')\n",
    "print(type(objSoup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T07:37:41.378813Z",
     "iopub.status.busy": "2023-09-15T07:37:41.378320Z",
     "iopub.status.idle": "2023-09-15T07:37:41.423182Z",
     "shell.execute_reply": "2023-09-15T07:37:41.421992Z",
     "shell.execute_reply.started": "2023-09-15T07:37:41.378776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "串列長度 4\n",
      "<div class=\"ywm_fi_cell\">\n",
      "<h4>統一黑馬基金</h4>\n",
      "<div class=\"ywm_fi_sec\">WMF001431</div>\n",
      "<div class=\"ywm_fi_sec\">台灣股票</div>\n",
      "</div>\n",
      "<div class=\"ywm_fi_cell\">\n",
      "<h4 class=\"red\">189.12<span>TWD</span></h4>\n",
      "<div class=\"ywm_fi_sec\">2023/09/14</div>\n",
      "</div>\n",
      "<div class=\"ywm_fi_cell\">\n",
      "<ul>\n",
      "<li>52周最高<span>203.7</span></li>\n",
      "<li>52周最低<span>104.65</span></li>\n",
      "</ul>\n",
      "<ul>\n",
      "<li>日漲跌<span class=\"red\">4.06</span></li>\n",
      "<li>漲跌幅<span class=\"red\">2.19 %</span></li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"ywm_fi_cell\">\n",
      "<div class=\"ywm_fi_btn\">\n",
      "<a class=\"ywm_fib01\" href=\"https://wealth.yuanta.com.tw/EC1200/EC120201.aspx?prodId=WMF001431\">單筆申購</a>\n",
      "<a class=\"ywm_fib02\" href=\"https://wealth.yuanta.com.tw/EC1200/EC120202.aspx?prodId=WMF001431\">定期定額</a>\n",
      "<a class=\"ywm_fib03\" href=\"https://wealth.yuanta.com.tw/EC1200/EC120203.aspx\">贖回</a>\n",
      "<a class=\"ywm_fib04\" href=\"https://wealth.yuanta.com.tw/EC1200/EC120206.aspx\">轉換</a>\n",
      "<a class=\"ywm_fib05\" href=\"javascript:AddtoObserved('WMF001431');\">加入觀察</a>\n",
      "</div>\n",
      "</div>\n",
      "淨值＝ [<h4 class=\"red\">189.12<span>TWD</span></h4>]\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "html=open('/kaggle/working/uni_hor.html',encoding='utf-8')\n",
    "objSoup=bs4.BeautifulSoup(html,'lxml')\n",
    "dataTag=objSoup.select('.ywm_fi_cell')\n",
    "print('串列長度',len(dataTag))\n",
    "#print('列印title = ',objSoup.title.text)\n",
    "for i in range(len(dataTag)):\n",
    "    print(dataTag[i])\n",
    "\n",
    "price=dataTag[1].find_all('h4',{'class':'red'})\n",
    "print('淨值＝',price)\n",
    "\n",
    "\n",
    "#print('列印Tag.string = ',objTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:58:25.414022Z",
     "iopub.status.busy": "2024-07-05T07:58:25.413435Z",
     "iopub.status.idle": "2024-07-05T07:58:38.692215Z",
     "shell.execute_reply": "2024-07-05T07:58:38.690835Z",
     "shell.execute_reply.started": "2024-07-05T07:58:25.413984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:24:24.408151Z",
     "iopub.status.busy": "2024-07-05T07:24:24.407769Z",
     "iopub.status.idle": "2024-07-05T07:24:26.433800Z",
     "shell.execute_reply": "2024-07-05T07:24:26.432361Z",
     "shell.execute_reply.started": "2024-07-05T07:24:24.408121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "網頁下載成功\n",
      "收盤日期為 2024/07/04\n",
      "淨值＝ 232.1TWD\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://wealth.yuanta.com.tw/WMECPortal/Wealth/Fundcenter/FundPage/60021903?'\n",
    "html = requests.get(url)\n",
    "html.raise_for_status()\n",
    "print('網頁下載成功')\n",
    "\n",
    "#html = open('/kaggle/working/uni_hor.html', encoding='utf-8')\n",
    "objSoup = bs4.BeautifulSoup(html.text, 'lxml')\n",
    "dateTag=objSoup.select('.ywm_fi_sec')\n",
    "#print('串列長度',len(dateTag))\n",
    "\n",
    "#for i in range(len(dateTag)):\n",
    "    #print(dateTag[i])\n",
    "\n",
    "date_element = dateTag[2]\n",
    "date_text = date_element.text  # 获取包含价格和\" TWD\" 的完整文本\n",
    "print('收盤日期為', date_text)\n",
    "\n",
    "    \n",
    "dataTag = objSoup.select('.ywm_fi_cell')\n",
    "#print('串列長度', len(dataTag))\n",
    "\n",
    "\n",
    "price_element = dataTag[1].find('h4', {'class': 'red'})\n",
    "price_text = price_element.text  # 获取包含价格和\" TWD\" 的完整文本\n",
    "price_parts = price_text.split()  # 将文本拆分成单词列表\n",
    "numeric_part = price_parts[0]  # 获取第一个单词（数字部分）\n",
    "price = numeric_part  # 将数字部分转换为浮点数\n",
    "print('淨值＝', price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyAutoGUI\n",
      "  Downloading PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
      "     -------------------------------------- 61.2/61.2 kB 542.5 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyscreeze>=0.1.21\n",
      "  Downloading PyScreeze-0.1.30.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pymsgbox\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytweening>=1.0.4\n",
      "  Downloading pytweening-1.2.0.tar.gz (171 kB)\n",
      "     -------------------------------------- 171.2/171.2 kB 2.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mouseinfo\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pygetwindow>=0.0.5\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyrect\n",
      "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\users\\dominic\\anaconda3\\lib\\site-packages (from pyscreeze>=0.1.21->PyAutoGUI) (9.2.0)\n",
      "Collecting pyperclip\n",
      "  Downloading pyperclip-1.9.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: PyAutoGUI, pygetwindow, pyscreeze, pytweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "  Building wheel for PyAutoGUI (pyproject.toml): started\n",
      "  Building wheel for PyAutoGUI (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for PyAutoGUI: filename=PyAutoGUI-0.9.54-py3-none-any.whl size=37597 sha256=ae860206a3704730df2d160ad1404ebeebb073f9d8c8e5317feadb3ca58f1cd0\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\29\\2b\\5f\\9df8525a15d14d1a3ba04fe66e5bd3d2dc8ca7f5fb2ab2ec50\n",
      "  Building wheel for pygetwindow (setup.py): started\n",
      "  Building wheel for pygetwindow (setup.py): finished with status 'done'\n",
      "  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11063 sha256=44d4c22233313d97a24278f5e1d01210510537aa7497ec730647227c6f7ba41b\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\44\\ab\\20\\423c3a444793767e4e41f8377bc902f77bee212e68dcce85a5\n",
      "  Building wheel for pyscreeze (pyproject.toml): started\n",
      "  Building wheel for pyscreeze (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyscreeze: filename=PyScreeze-0.1.30-py3-none-any.whl size=14399 sha256=307d82b031e417dde0e216fbfe0158f7db3e0cc9b73ddd38078baf56677c56ad\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\57\\ef\\26\\25869f8f3fbfc108d6d5a50f57184291825caedc8ab1eaa1d6\n",
      "  Building wheel for pytweening (setup.py): started\n",
      "  Building wheel for pytweening (setup.py): finished with status 'done'\n",
      "  Created wheel for pytweening: filename=pytweening-1.2.0-py3-none-any.whl size=8010 sha256=00d751ad698f1ba7fe7371c0e6bc88d8c0f34b14a749da13068e3d1ea095833e\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\eb\\48\\3d\\ded50b5e7d57738e4bd3ee314e537f4f646328aeaef51d2619\n",
      "  Building wheel for mouseinfo (setup.py): started\n",
      "  Building wheel for mouseinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10891 sha256=5cc6c05284e4b44415a362183fad4fa1d49d5907160de0495f86a0647064e667\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\61\\73\\b9\\6fb1131ab36e650206e3aa0ad7a68907b41b32ac2d4f75f543\n",
      "  Building wheel for pymsgbox (pyproject.toml): started\n",
      "  Building wheel for pymsgbox (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7416 sha256=10c1694229369538a6cc0a56929b041d6b885eed9ef61b3c8069c8617248a184\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\7f\\13\\8c\\584c519464297d9637f9cd29fd1dcdf55e2a2cab225c76a2db\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.9.0-py3-none-any.whl size=11002 sha256=8c3887ab85372e708e98b9ec1c7b7fd63fe93a1a897c4ae186f5b8fb41973ba3\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\b2\\12\\87\\f136269baa23c0afc652d05f3bd48834f4f6658b42365036c7\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.2.0-py2.py3-none-any.whl size=11179 sha256=e97a3173d46e82684f9e14bfd1af2babd272ce1d623c55647972937879e4c7c5\n",
      "  Stored in directory: c:\\users\\dominic\\appdata\\local\\pip\\cache\\wheels\\25\\80\\fa\\27bb4a1c2e21f64ec71390489d52e57b7cc8afbe79bd595c5e\n",
      "Successfully built PyAutoGUI pygetwindow pyscreeze pytweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: pytweening, pyrect, pyperclip, pymsgbox, pyscreeze, pygetwindow, mouseinfo, PyAutoGUI\n",
      "Successfully installed PyAutoGUI-0.9.54 mouseinfo-0.1.3 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.9.0 pyrect-0.2.0 pyscreeze-0.1.30 pytweening-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyAutoGUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uTRd8WZAkORjjq5AYTwWqSCx7MuKMrzX9N9FiqkehsX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_message(msg, image_path):\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer uTRd8WZAkORjjq5AYTwWqSCx7MuKMrzX9N9FiqkehsX'\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        'message': msg\n",
    "    }\n",
    "    files = {\n",
    "        'imageFile': open(image_path, 'rb')\n",
    "    }\n",
    "\n",
    "    r = requests.post(\"https://notify-api.line.me/api/notify\", headers=headers, data=payload, files=files)\n",
    "    return r.status_code, r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "狀態碼: 200\n"
     ]
    }
   ],
   "source": [
    "# 訊息和圖片路徑\n",
    "msg = 'test'\n",
    "imgfile = r'C:/Users/Dominic/Desktop/小說集/家裡蹲妹妹竟然要當冒險者/03447-3233128412-blue cloak.png'\n",
    "\n",
    "status_code, response_data = send_message(msg, imgfile)\n",
    "print(f\"狀態碼: {status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過取得世芯-KY、奇鋐及台積電的每日開盤、收盤、成交量，決定黑馬將是大紅或大綠。\n",
    "\n",
    "之後可以建立機器學習模型，配對什麼情況下的黑馬是可進場的。搭配line機器人，回報可否進場。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "symboldict={'3661':'世芯-KY','3017':'奇鋐','2330':'台積電'}\n",
    "\n",
    "#民國轉西元年函數\n",
    "def transform_date(date):\n",
    "    parts = date.split('/') \n",
    "    y, m, d = parts\n",
    "    return str(int(y) + 1911) + '/' + m + '/' + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(begin,stocks):\n",
    "    print('start...')\n",
    "    \n",
    "    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    #目標網址\n",
    "    baseurl='https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY?date={}&stockNo={}&response=html'.format(begin,stocks)\n",
    "    \n",
    "    #加上content可以解決某些回傳失敗問題\n",
    "    data=requests.get(url=baseurl,headers=headers).content\n",
    "    #title=BeautifulSoup(data,'html.parser').find('thead').find('tr')\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    title = soup.find('thead')\n",
    "    if title is None:\n",
    "        raise ValueError(f\"Could not find table header (thead) in the data for {stocks} on {begin}\")\n",
    "    \n",
    "    title_row = title.find('tr')\n",
    "    if title_row is None:\n",
    "        raise ValueError(f\"Could not find table row (tr) in the table header for {stocks} on {begin}\")\n",
    "    \n",
    "    \n",
    "    datalist=[]\n",
    "    for col in title_row.find_all_next('tr'):\n",
    "        datalist.append([row.text for row in col.find_all('td')])\n",
    "        \n",
    "    \n",
    "    #刪除第一行不需要的數據\n",
    "    for each in datalist[1:]:\n",
    "        each[0]=transform_date(each[0])\n",
    "    \n",
    "    #print(datalist[1:])\n",
    "    #print(datalist[1:2])\n",
    "    df=pd.DataFrame(datalist[1:],columns=datalist[1])\n",
    "    df.columns=datalist[1]\n",
    "    \n",
    "    print('{}{}_{}資料搜集成功'.format(stocks,symboldict[stocks],begin))\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_to_csv(input_dataframe,stocks):\n",
    "    directory = 'uniblack_stocks'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    #確認該股票檔案是否存在\n",
    "    if os.path.isfile('{}{}.csv'.format(stocks,symboldict[stocks])):\n",
    "        #用異常處理讀取檔案，藉此檢查是否有問題 \n",
    "        try:\n",
    "            cu_data=pd.read_csv('{}{}.csv'.format(stocks,symboldict[stocks]))\n",
    "            \n",
    "            if input_dataframe['日期'][0] in list(cu_data['日期']):\n",
    "                print('資料檢查結果：有重複日期')\n",
    "                print('不寫入')\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                print('資料檢查結果：無重複資料...寫入中...')\n",
    "                filepath = os.path.join(directory, '{}{}.csv'.format(stocks, symboldict[stocks]))\n",
    "                input_dataframe.to_csv(filepath,mode='a',header=False)\n",
    "                #input_dataframe.to_csv('{}{}.csv'.format(stocks,symboldict[stocks]),mode='a',header=False)\n",
    "                print('寫入完成！')\n",
    "                time.sleep(1)\n",
    "        except:\n",
    "            print('某步驟錯誤')\n",
    "    else:\n",
    "        print('創建新資料...')\n",
    "        filepath = os.path.join(directory, '{}{}.csv'.format(stocks, symboldict[stocks]))\n",
    "        input_dataframe.to_csv(filepath, mode='a',header=False)\n",
    "        #input_dataframe.to_csv('{}{}.csv'.format(stocks,symboldict[stocks]),mode='w')\n",
    "        \n",
    "        print('寫入完成！')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_datetime(start_year, start_month, end_year, end_month):\n",
    "    year_list = []\n",
    "\n",
    "    for i in range(end_year - start_year + 1):\n",
    "        year_list.append(start_year + i)\n",
    "\n",
    "    whole_date = []\n",
    "    for strtime in year_list:\n",
    "        if strtime == start_year and strtime != end_year:\n",
    "            #aa='進入那裡'\n",
    "            for mon in range(start_month, 13):\n",
    "                if mon > 9:\n",
    "                    str_sm = mon\n",
    "                    whole_date.append('{}{}01'.format(strtime, str_sm))\n",
    "                elif mon <= 9:\n",
    "                    str_sm = '0{}'.format(mon)\n",
    "                    whole_date.append('{}{}01'.format(strtime, str_sm))\n",
    "                else:\n",
    "                    print('請輸入1-12')\n",
    "        elif strtime == end_year and start_month != end_month:\n",
    "            #aa='進入這裡'\n",
    "            for mon in range(1, end_month + 1):\n",
    "                if mon > 9:\n",
    "                    end_sm = mon\n",
    "                    whole_date.append('{}{}01'.format(strtime, end_sm))\n",
    "                elif mon <= 9:\n",
    "                    end_sm = '0{}'.format(mon)\n",
    "                    whole_date.append('{}{}01'.format(strtime, end_sm))\n",
    "                else:\n",
    "                    print('請輸入1-12')\n",
    "        else:\n",
    "            for nor_mon in range(start_month, end_month+1):\n",
    "                #aa='進入nor_mon'\n",
    "                if nor_mon > 9:\n",
    "                    nor_m = nor_mon\n",
    "                    whole_date.append('{}{}01'.format(strtime, nor_m))\n",
    "                elif nor_mon <= 9:\n",
    "                    whole_date.append('{}0{}01'.format(strtime, nor_mon))\n",
    "                else:\n",
    "                    print('請輸入1-12')\n",
    "\n",
    "    return whole_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start...\n",
      "3661世芯-KY_20230101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230301資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230401資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230501資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230601資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230701資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230801資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20230901資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20231001資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20231101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20231201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240301資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240401資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240501資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240601資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3661世芯-KY_20240701資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230301資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230401資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230501資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230601資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230701資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230801資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20230901資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20231001資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20231101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20231201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240301資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240401資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240501資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240601資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "3017奇鋐_20240701資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230301資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230401資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230501資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230601資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230701資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230801資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20230901資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20231001資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20231101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20231201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240101資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240201資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240301資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240401資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240501資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240601資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n",
      "start...\n",
      "2330台積電_20240701資料搜集成功\n",
      "創建新資料...\n",
      "寫入完成！\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "code=['3661','3017','2330']\n",
    "cralwer_date=diff_datetime(2023,1,2024,7)\n",
    "#print(cralwer_date)\n",
    "\n",
    "for sn in code:\n",
    "    for dn in cralwer_date:\n",
    "        data_to_csv(get_data(dn,sn),sn)\n",
    "        time.sleep(3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20240701']\n"
     ]
    }
   ],
   "source": [
    "print(diff_datetime(2024,7,2024,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start...\n",
      "3661世芯-KY_20240701資料搜集成功\n",
      "start...\n",
      "3017奇鋐_20240701資料搜集成功\n",
      "start...\n",
      "2330台積電_20240701資料搜集成功\n",
      "aaa: [   2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00  \\\n",
      "0  2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00   \n",
      "1  2024/07/02  1,641,346  4,051,285,435  2,470.00  2,510.00  2,445.00   \n",
      "2  2024/07/03  2,216,019  5,476,201,385  2,485.00  2,535.00  2,440.00   \n",
      "3  2024/07/04  3,030,115  7,728,894,730  2,495.00  2,620.00  2,485.00   \n",
      "4  2024/07/05  2,928,024  7,463,372,970  2,615.00  2,625.00  2,510.00   \n",
      "\n",
      "   2,495.00   +40.00   6,157  \n",
      "0  2,495.00   +40.00   6,157  \n",
      "1  2,455.00   -40.00   7,406  \n",
      "2  2,470.00   +15.00   7,339  \n",
      "3  2,615.00  +145.00  10,481  \n",
      "4  2,525.00   -90.00  14,219  ]\n",
      "bbb: [   2024/07/01  15,583,669  11,937,347,985  765.00  786.00  741.00  743.00  \\\n",
      "0  2024/07/01  15,583,669  11,937,347,985  765.00  786.00  741.00  743.00   \n",
      "1  2024/07/02  11,471,651   8,549,117,187  743.00  756.00  730.00  752.00   \n",
      "2  2024/07/03  13,049,882   9,867,177,364  757.00  770.00  743.00  745.00   \n",
      "3  2024/07/04   8,633,055   6,523,013,594  758.00  768.00  748.00  752.00   \n",
      "4  2024/07/05   7,951,054   6,030,438,595  759.00  767.00  748.00  764.00   \n",
      "\n",
      "   -22.00  25,608  \n",
      "0  -22.00  25,608  \n",
      "1   +9.00  12,071  \n",
      "2   -7.00  14,855  \n",
      "3   +7.00   9,071  \n",
      "4  +12.00  10,116  ]\n",
      "ccc: [   2024/07/01  20,936,005  20,320,957,284    968.00    977.00    965.00  \\\n",
      "0  2024/07/01  20,936,005  20,320,957,284    968.00    977.00    965.00   \n",
      "1  2024/07/02  27,992,930  26,971,516,491    967.00    971.00    959.00   \n",
      "2  2024/07/03  25,022,531  24,386,705,873    976.00    979.00    967.00   \n",
      "3  2024/07/04  47,251,502  47,347,126,144  1,000.00  1,010.00    997.00   \n",
      "4  2024/07/05  21,735,614  21,827,958,195  1,005.00  1,010.00  1,000.00   \n",
      "\n",
      "     968.00   +2.00  38,293  \n",
      "0    968.00   +2.00  38,293  \n",
      "1    960.00   -8.00  38,928  \n",
      "2    979.00  +19.00  36,096  \n",
      "3  1,005.00  +26.00  92,002  \n",
      "4  1,005.00    0.00  35,802  ]\n"
     ]
    }
   ],
   "source": [
    "# 初始化變量\n",
    "code = ['3661', '3017', '2330']\n",
    "dataframes = [None, None, None]\n",
    "cralwer_date = diff_datetime(2024, 7, 2024, 7)\n",
    "\n",
    "# 爬取數據\n",
    "for sn, idx in zip(code, range(len(dataframes))):\n",
    "    df_list = []\n",
    "    for dn in cralwer_date:\n",
    "        data = get_data(dn, sn)\n",
    "        df_list.append(data)\n",
    "        time.sleep(3)\n",
    "    dataframes[idx] = df_list\n",
    "\n",
    "# 將結果賦值給aaa,bbb,ccc\n",
    "aaa, bbb, ccc = dataframes\n",
    "\n",
    "# 打印結果\n",
    "print(\"aaa:\", aaa)\n",
    "print(\"bbb:\", bbb)\n",
    "print(\"ccc:\", ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00  \\\n",
       " 0  2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00   \n",
       " 1  2024/07/02  1,641,346  4,051,285,435  2,470.00  2,510.00  2,445.00   \n",
       " 2  2024/07/03  2,216,019  5,476,201,385  2,485.00  2,535.00  2,440.00   \n",
       " 3  2024/07/04  3,030,115  7,728,894,730  2,495.00  2,620.00  2,485.00   \n",
       " 4  2024/07/05  2,928,024  7,463,372,970  2,615.00  2,625.00  2,510.00   \n",
       " \n",
       "    2,495.00   +40.00   6,157  \n",
       " 0  2,495.00   +40.00   6,157  \n",
       " 1  2,455.00   -40.00   7,406  \n",
       " 2  2,470.00   +15.00   7,339  \n",
       " 3  2,615.00  +145.00  10,481  \n",
       " 4  2,525.00   -90.00  14,219  ]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,615.00 2,625.00 2,510.00 2,525.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ddf=pd.DataFrame(aaa[-1:])\n",
    "\n",
    "# 过滤日期为2024/07/05的行\n",
    "filtered_row = ddf[ddf['2024/07/01'] == '2024/07/05']\n",
    "\n",
    "# 提取所需列的数据\n",
    "open_price = filtered_row['2,470.00'].values[0]\n",
    "high_price = filtered_row['2,510.00'].values[0]\n",
    "low_price = filtered_row['2,425.00'].values[0]\n",
    "close_price = filtered_row['2,495.00'].values[0]\n",
    "\n",
    "# 打印结果\n",
    "print(open_price, high_price, low_price, close_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00  \\\n",
      "0  2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00   \n",
      "1  2024/07/02  1,641,346  4,051,285,435  2,470.00  2,510.00  2,445.00   \n",
      "2  2024/07/03  2,216,019  5,476,201,385  2,485.00  2,535.00  2,440.00   \n",
      "3  2024/07/04  3,030,115  7,728,894,730  2,495.00  2,620.00  2,485.00   \n",
      "4  2024/07/05  2,928,024  7,463,372,970  2,615.00  2,625.00  2,510.00   \n",
      "\n",
      "   2,495.00   +40.00   6,157  \n",
      "0  2,495.00   +40.00   6,157  \n",
      "1  2,455.00   -40.00   7,406  \n",
      "2  2,470.00   +15.00   7,339  \n",
      "3  2,615.00  +145.00  10,481  \n",
      "4  2,525.00   -90.00  14,219  \n"
     ]
    }
   ],
   "source": [
    "print(aaa[-1:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data format error in: [   2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00  \\\n",
      "0  2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00  2,425.00   \n",
      "1  2024/07/02  1,641,346  4,051,285,435  2,470.00  2,510.00  2,445.00   \n",
      "2  2024/07/03  2,216,019  5,476,201,385  2,485.00  2,535.00  2,440.00   \n",
      "3  2024/07/04  3,030,115  7,728,894,730  2,495.00  2,620.00  2,485.00   \n",
      "4  2024/07/05  2,928,024  7,463,372,970  2,615.00  2,625.00  2,510.00   \n",
      "\n",
      "   2,495.00   +40.00   6,157  \n",
      "0  2,495.00   +40.00   6,157  \n",
      "1  2,455.00   -40.00   7,406  \n",
      "2  2,470.00   +15.00   7,339  \n",
      "3  2,615.00  +145.00  10,481  \n",
      "4  2,525.00   -90.00  14,219  ]\n",
      "Data format error in: [   2024/07/01  15,583,669  11,937,347,985  765.00  786.00  741.00  743.00  \\\n",
      "0  2024/07/01  15,583,669  11,937,347,985  765.00  786.00  741.00  743.00   \n",
      "1  2024/07/02  11,471,651   8,549,117,187  743.00  756.00  730.00  752.00   \n",
      "2  2024/07/03  13,049,882   9,867,177,364  757.00  770.00  743.00  745.00   \n",
      "3  2024/07/04   8,633,055   6,523,013,594  758.00  768.00  748.00  752.00   \n",
      "4  2024/07/05   7,951,054   6,030,438,595  759.00  767.00  748.00  764.00   \n",
      "\n",
      "   -22.00  25,608  \n",
      "0  -22.00  25,608  \n",
      "1   +9.00  12,071  \n",
      "2   -7.00  14,855  \n",
      "3   +7.00   9,071  \n",
      "4  +12.00  10,116  ]\n",
      "Data format error in: [   2024/07/01  20,936,005  20,320,957,284    968.00    977.00    965.00  \\\n",
      "0  2024/07/01  20,936,005  20,320,957,284    968.00    977.00    965.00   \n",
      "1  2024/07/02  27,992,930  26,971,516,491    967.00    971.00    959.00   \n",
      "2  2024/07/03  25,022,531  24,386,705,873    976.00    979.00    967.00   \n",
      "3  2024/07/04  47,251,502  47,347,126,144  1,000.00  1,010.00    997.00   \n",
      "4  2024/07/05  21,735,614  21,827,958,195  1,005.00  1,010.00  1,000.00   \n",
      "\n",
      "     968.00   +2.00  38,293  \n",
      "0    968.00   +2.00  38,293  \n",
      "1    960.00   -8.00  38,928  \n",
      "2    979.00  +19.00  36,096  \n",
      "3  1,005.00  +26.00  92,002  \n",
      "4  1,005.00    0.00  35,802  ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 將數據轉換為DataFrame並處理\n",
    "data_list = [aaa, bbb, ccc]\n",
    "column_names = ['date', 'volume', 'amount', 'open', 'high', 'low', 'close', 'change', 'transactions']\n",
    "\n",
    "for data in data_list:\n",
    "    # 確保數據是二維列表格式\n",
    "    if isinstance(data, list) and all(isinstance(row, list) for row in data):\n",
    "        df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "        # 過濾日期為2024/07/05的行\n",
    "        filtered_row = df[df['date'] == '2024/07/05']\n",
    "\n",
    "        if not filtered_row.empty:\n",
    "            # 提取所需列的數據\n",
    "            open_price = filtered_row['open'].values[0]\n",
    "            high_price = filtered_row['high'].values[0]\n",
    "            low_price = filtered_row['low'].values[0]\n",
    "            close_price = filtered_row['close'].values[0]\n",
    "\n",
    "            # 打印結果\n",
    "            print(open_price, high_price, low_price, close_price)\n",
    "    else:\n",
    "        print(\"Data format error in:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -X POST https://notify-api.line.me/api/notify -H \"Authorization: Bearer uTRd8WZAkORjjq5AYTwWqSCx7MuKMrzX9N9FiqkehsX\" -F \"message=test\" -F \"imageFile=@Desktop/uniblack_ana/hist_fund_predict.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "import datetime\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 設定價格\n",
    "open_price = 2615.00\n",
    "high_price = 2625.00\n",
    "low_price = 2510.00\n",
    "close_price = 2525.00\n",
    "\n",
    "# 設定圖表\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 設定日期\n",
    "date = datetime.datetime.now()\n",
    "\n",
    "# 設定K棒的顏色\n",
    "color = 'red' if close_price < open_price else 'green'\n",
    "\n",
    "# 繪製K棒\n",
    "ax.plot([date, date], [low_price, high_price], color='black')\n",
    "rect = Rectangle(\n",
    "    (mdates.date2num(date) - 0.1, min(open_price, close_price)),\n",
    "    0.2,\n",
    "    abs(open_price - close_price),\n",
    "    color=color\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# 設定日期格式和間隔\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "\n",
    "# 設定圖表標題和軸標題\n",
    "ax.set_title('K plot')\n",
    "ax.set_xlabel('date')\n",
    "ax.set_ylabel('price')\n",
    "\n",
    "# 旋轉日期標籤\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 設定適當的字體\n",
    "font_path = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "for font in font_path:\n",
    "    if \"SimSun\" in font:  # 找到中文字体SimSun\n",
    "        prop = fm.FontProperties(fname=font)\n",
    "        plt.rcParams['font.family'] = prop.get_name()\n",
    "        break\n",
    "\n",
    "# 顯示圖表\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下載成功\n",
      "16799\n",
      "以uniblack_stocks/uni_hor.html儲存網頁HTML檔案成功\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://fund.taipeifubon.com.tw/w/wr/wr02_ACPS02-0603.djhtm'\n",
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "try:\n",
    "    htmlfile = requests.get(url, headers=headers)\n",
    "    print('下載成功')\n",
    "except Exception as err:\n",
    "    print('下載網頁失敗:%s'% err)\n",
    "    \n",
    "fn = 'uniblack_stocks/uni_hor.html'\n",
    "with open(fn,'wb') as file_obj:\n",
    "    for diskStorage in htmlfile.iter_content(40960):\n",
    "        size=file_obj.write(diskStorage)\n",
    "        print(size)\n",
    "    print('以%s儲存網頁HTML檔案成功'%fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: Big5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Printing HTML: 100%|██████████| 810/810 [00:00<00:00, 269955.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE >\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      " <head>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <script src=\"/w/js/jquery-latest.djjs\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"/w/js/Applet2Canvas.djjs\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"/w/js/DJWebGraph.djjs\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <title>\n",
      "   國內基金淨值表\n",
      "  </title>\n",
      "  <link href=\"/w/js/wFund.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <script language=\"JavaScript\" src=\"/w/js/cookie.js\">\n",
      "  </script>\n",
      "  <script language=\"JavaScript\" src=\"/w/js/wtfundjs.djjs\">\n",
      "  </script>\n",
      "  <script language=\"JavaScript\" src=\"/w/js/wtfund.js\">\n",
      "  </script>\n",
      "  <script language=\"JavaScript\" src=\"/w/js/jsFunction.js\">\n",
      "  </script>\n",
      "  <script src=\"/w/js/jquery-ui/jquery-ui.min.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <link href=\"/w/js/jquery-ui/jquery-ui.css\" rel=\"stylesheet\"/>\n",
      "  <script language=\"JavaScript\">\n",
      "   <!--\n",
      "CheckMenu('wr02','ACPS02','NA','NA');\n",
      "// -->\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <script language=\"javascript\" src=\"/w/js/SU.js\">\n",
      "  </script>\n",
      "  <center>\n",
      "   <div id=\"buyFundDialog\" style=\"display: none;\" title=\"申購方式\">\n",
      "    <p>\n",
      "    </p>\n",
      "    請選擇下列申購方式\n",
      "   </div>\n",
      "   <div id=\"SysJustIFRAMEDIV\">\n",
      "    <table border=\"0\" width=\"680\">\n",
      "     <tr>\n",
      "      <td class=\"wfb00c\">\n",
      "       <script language=\"javascript\">\n",
      "        <!--\n",
      "window.onload = GoStart;\n",
      "\n",
      "function GoStart()\n",
      "{\n",
      "\tComboReset('ACPS02-0603');\n",
      "}\n",
      "\n",
      "function FundGoPage(sObj)\n",
      "{\n",
      "\tvar sURL = '/w/wr/wr02.djhtm?a=';\n",
      "\tvar sFID = sObj.selTFund3.options[sObj.selTFund3.selectedIndex].value;\n",
      "\tif ( sFID != '0' )\n",
      "\t\tdocument.location = sURL + sFID;\n",
      "}\n",
      "//-->\n",
      "       </script>\n",
      "       <table border=\"0\" cellpadding=\"1\" cellspacing=\"1\" class=\"wfb0c\" id=\"oMainTable\" style=\"border-collapse: separate\" width=\"680\">\n",
      "        <form method=\"POST\" name=\"wr02_frm\">\n",
      "         <div class=\"tabs\">\n",
      "          <ul>\n",
      "           <li class=\"\">\n",
      "            <a href=\"/w/wr/wr01_ACPS02-0603.djhtm\">\n",
      "             基本資料\n",
      "            </a>\n",
      "           </li>\n",
      "           <li class=\"on\">\n",
      "            <a href=\"/w/wr/wr02_ACPS02-0603.djhtm\">\n",
      "             淨值走勢\n",
      "            </a>\n",
      "           </li>\n",
      "           <li class=\"\">\n",
      "            <a href=\"/w/wr/wr03_ACPS02-0603.djhtm\">\n",
      "             績效分析\n",
      "            </a>\n",
      "           </li>\n",
      "           <li class=\"\">\n",
      "            <a href=\"/w/wr/wr04_ACPS02-0603.djhtm\">\n",
      "             持股狀況\n",
      "            </a>\n",
      "           </li>\n",
      "           <li class=\"\">\n",
      "            <a href=\"/w/wr/wr10_ACPS02-0603.djhtm\">\n",
      "             配息紀錄\n",
      "            </a>\n",
      "           </li>\n",
      "          </ul>\n",
      "         </div>\n",
      "         <script language=\"javascript\" src=\"/w/js/WtFundlistJS.djjs\">\n",
      "         </script>\n",
      "         <tr id=\"oScrollHead\">\n",
      "          <td class=\"wfb1c\" colspan=\"2\">\n",
      "           <script language=\"javascript\">\n",
      "            <!--\n",
      " var sObj = eval('document.' + 'wr02_frm'); \n",
      "\tiID = 'ACPS02-0603';\n",
      "\tGenFundCorpCombo('BFZPSA','ACPS02-0603','wr02_frm');\n",
      "\tfor (i=0;i<sObj.selTFund_corp.options.length;i++)\n",
      "\t{\n",
      "\t\tvar tmpID1 = sObj.selTFund_corp.options[i].value.toUpperCase();\n",
      "\t\tif (tmpID1 == 'BFZPSA') \n",
      "\t\t{\n",
      "\t\t\tsObj.selTFund_corp.selectedIndex = i;\n",
      "\t\t\tbreak;\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor (i=0;i<sObj.selTFund3.options.length;i++)\n",
      "\t{\n",
      "\t\tvar tmpID2 = sObj.selTFund3.options[i].value.toUpperCase();\n",
      "\t\tif (iID != '')\n",
      "\t\t{\n",
      "\t\t\tif (tmpID2 == iID )\n",
      "\t\t\t{\n",
      "\t\t\t\tsObj.selTFund3.selectedIndex = i;\n",
      "\t\t\t\tbreak;\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\telse\n",
      "\t\t\tsObj.selTFund3.selectedIndex = 0;\n",
      "\t}\n",
      "//-->\n",
      "           </script>\n",
      "           <!--FundBuyBtn-->\n",
      "          </td>\n",
      "         </tr>\n",
      "         <tr>\n",
      "          <td class=\"wfb3c\" colspan=\"2\">\n",
      "           <table border=\"0\" cellpadding=\"1\" cellspacing=\"1\" class=\"wfb3l\" width=\"100%\">\n",
      "            <td class=\"wfb3c\" rowspan=\"2\">\n",
      "             請選擇期間\n",
      "            </td>\n",
      "            <td class=\"wfb3l\">\n",
      "             <input checked=\"\" name=\"radioMonth\" onclick=\"javascript:radioSelYear_onclick(true);\" type=\"radio\"/>\n",
      "             <select name=\"selYEAR\" onchange=\"javascript:SelYear_onChange(true,this.selectedIndex);\">\n",
      "              <option>\n",
      "               ＸＸＸＸＸ\n",
      "              </option>\n",
      "             </select>\n",
      "            </td>\n",
      "            <td class=\"wfb3c\" rowspan=\"2\">\n",
      "             <input name=\"BB1\" onclick=\"javascript:jumpgo();\" type=\"button\" value=\"開始查詢\"/>\n",
      "            </td>\n",
      "            <tr>\n",
      "             <td class=\"wfb3l\">\n",
      "              <input name=\"radioMonth\" onclick=\"javascript:radioSelYear_onclick(false);\" type=\"radio\"/>\n",
      "              <script language=\"JavaScript\" src=\"/w/js/month.js\">\n",
      "              </script>\n",
      "              從\n",
      "              <select name=\"Y2\" onchange=\"javascript:SetMonthDate(document.wr02_frm.Y2,document.wr02_frm.M2,document.wr02_frm.D2);\">\n",
      "               <option value=\"91\">\n",
      "               </option>\n",
      "              </select>\n",
      "              年\n",
      "              <select name=\"M2\" onchange=\"javascript:SetMonthDate(document.wr02_frm.Y2,document.wr02_frm.M2,document.wr02_frm.D2);\">\n",
      "               <option value=\"-1\">\n",
      "               </option>\n",
      "              </select>\n",
      "              月\n",
      "              <select name=\"D2\">\n",
      "               <option value=\"-1\">\n",
      "               </option>\n",
      "              </select>\n",
      "              日至\n",
      "              <select name=\"Y1\" onchange=\"javascript:SetMonthDate(document.wr02_frm.Y1,document.wr02_frm.M1,document.wr02_frm.D1);\">\n",
      "               <option value=\"91\">\n",
      "               </option>\n",
      "              </select>\n",
      "              年\n",
      "              <select name=\"M1\" onchange=\"javascript:SetMonthDate(document.wr02_frm.Y1,document.wr02_frm.M1,document.wr02_frm.D1);\">\n",
      "               <option value=\"-1\">\n",
      "               </option>\n",
      "              </select>\n",
      "              月\n",
      "              <select name=\"D1\">\n",
      "               <option value=\"-1\">\n",
      "               </option>\n",
      "              </select>\n",
      "              日\n",
      "              <script language=\"javascript\">\n",
      "               <!--\n",
      "\tvar getYMD1 = '2024-7-9';\n",
      "\tvar getYMD2 = '2023-7-9';\n",
      "   PageInit(document.wr02_frm);\n",
      "   function PageInit(obj){\t\t//在 BODY onLoad 時候的初始化\n",
      "\t\tShowYear(obj.Y1);\t\t\t\t\t\t\n",
      "\t\tShowYear(obj.Y2);\t\t\t\t\t\t\n",
      "\t\tSetOptionValue(obj.M1,1,12);\t\t\n",
      "\t\tSetOptionValue(obj.M2,1,12);\t\t\n",
      "\t\t//設定初始值\t\t\t\t\t\t\n",
      "\t\tvar YMDary1 = getYMD1.split('-');\t\n",
      "\t\tSetFocus(obj.Y1,YMDary1[0]);   \n",
      "\t\tSetFocus(obj.M1,YMDary1[1]);\t\t\n",
      "\t\tvar YMDary2 = getYMD2.split('-');\t\n",
      "\t\tSetFocus(obj.Y2,YMDary2[0]);   \n",
      "\t\tSetFocus(obj.M2,YMDary2[1]);\t\t\n",
      "\t\tSetMonthDate(obj.Y1,obj.M1,obj.D1);\t\t\n",
      "\t\tSetMonthDate(obj.Y2,obj.M2,obj.D2);\t\t\n",
      "\t\tSetFocus(obj.D2,YMDary2[2]);\t\t\n",
      "\t\tSetFocus(obj.D1,YMDary1[2]);\t\t\n",
      "\t}\t\t\t\t\t\t\t\t\t\t\n",
      "  function CheckSubmit (){\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tvar Frm = document.wr02_frm;\t\t\t\t\t\t\t\t\t\t\n",
      "       var y1 = parseInt(Frm.Y1.options[Frm.Y1.selectedIndex].value);\t\n",
      "      \tvar m1 = parseInt(Frm.M1.options[Frm.M1.selectedIndex].value);\t\n",
      "      \tvar d1 = parseInt(Frm.D1.options[Frm.D1.selectedIndex].value);\t\n",
      "       var y2 = parseInt(Frm.Y2.options[Frm.Y2.selectedIndex].value);\t\n",
      "      \tvar m2 = parseInt(Frm.M2.options[Frm.M2.selectedIndex].value);\t\n",
      "      \tvar d2 = parseInt(Frm.D2.options[Frm.D2.selectedIndex].value);\t\n",
      "      \tvar sEDate = y1+'-'+m1+'-' + d1;\t\t\t\t\t\t\t\n",
      "      \tvar sBDate = y2+'-'+m2+'-' + d2;\t\t\t\t\t\t\t\n",
      "      \tif(checkBEdate(sBDate,sEDate)){\t\t\t\t\t\t\t\t\n",
      "\t\t\treturn sBDate + '_' + sEDate;\t\t\t\t\t\t\t\n",
      "\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\telse\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\treturn 'false';\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "  function checkBEdate(sBDate,sEDate){\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\tvar aymd1 = sBDate.split('-');\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\tvar aymd2 = sEDate.split('-');\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "   if (aymd1.length < 3 || aymd2.length < 3 ) {\t\t\t\t\t\t\t\t\t\n",
      "\t\t\talert ('日期選擇錯誤!!');\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\treturn false;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "   var nbdate = parseInt(aymd1[0])*10000+parseInt(aymd1[1])*100+parseInt(aymd1[2]);\n",
      "   var nedate = parseInt(aymd2[0])*10000+parseInt(aymd2[1])*100+parseInt(aymd2[2]);\n",
      "   if (nbdate > nedate) {\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\talert('您所輸入的起始日期大於結束日期');\t\t\t\t\t\t\t\t\t\n",
      "\t\t\treturn false;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t    return true;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "   }\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "//-->\n",
      "              </script>\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "          </td>\n",
      "         </tr>\n",
      "         <tr>\n",
      "          <td class=\"wfb5c\" colspan=\"2\">\n",
      "           <div id=\"SysJustWebGraphDIV\">\n",
      "           </div>\n",
      "          </td>\n",
      "         </tr>\n",
      "         <tr>\n",
      "          <td class=\"wfb1c\" colspan=\"2\">\n",
      "           統一黑馬基金-近30日淨值\n",
      "          </td>\n",
      "         </tr>\n",
      "         <tr>\n",
      "          <td class=\"wfb2c\" width=\"50%\">\n",
      "           <table cellpadding=\"1\" cellspacing=\"1\" class=\"wfb0c\" width=\"100%\">\n",
      "            <tr>\n",
      "             <td class=\"wfb3c\">\n",
      "              日期\n",
      "             </td>\n",
      "             <td class=\"wfb3c\">\n",
      "              淨值\n",
      "             </td>\n",
      "             <td class=\"wfb3c\">\n",
      "              漲/跌\n",
      "             </td>\n",
      "             <td class=\"wfb3c\">\n",
      "              漲跌幅(%)\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/07/09\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              236.31\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              1.76\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.75\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/07/08\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              234.55\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.56\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.24\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/07/05\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              235.11\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              3.01\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              1.3\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/07/04\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              232.10\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              4.32\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              1.9\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/07/03\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              227.78\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              2.17\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.96\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/07/02\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              225.61\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.85\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.38\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/07/01\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              226.46\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -2.45\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -1.07\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/28\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              228.91\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              3.19\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              1.41\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/27\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              225.72\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.96\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.42\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/26\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              226.68\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              4.15\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              1.86\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/25\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              222.53\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.17\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.08\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/24\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              222.36\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -5.42\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -2.38\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/21\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              227.78\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -2.67\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -1.16\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/20\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              230.45\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              3.81\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              1.68\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/19\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              226.64\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              1.53\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.68\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "          </td>\n",
      "          <td class=\"wfb2c\" width=\"50%\">\n",
      "           <table cellpadding=\"1\" cellspacing=\"1\" class=\"wfb0c\" width=\"100%\">\n",
      "            <tr>\n",
      "             <td class=\"wfb3c\">\n",
      "              日期\n",
      "             </td>\n",
      "             <td class=\"wfb3c\">\n",
      "              淨值\n",
      "             </td>\n",
      "             <td class=\"wfb3c\">\n",
      "              漲/跌\n",
      "             </td>\n",
      "             <td class=\"wfb3c\">\n",
      "              漲跌幅(%)\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/18\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              225.11\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.51\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.23\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/17\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              225.62\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.83\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.37\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/14\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              226.45\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              2.86\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              1.28\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/13\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              223.59\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              2.26\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              1.02\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/12\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              221.33\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              3.53\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              1.62\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/11\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              217.80\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.27\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.12\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/07\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              218.07\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.84\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.38\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/06\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              218.91\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              0.72\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              0.33\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/05\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              218.19\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.16\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -0.07\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/06/04\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              218.35\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -1.78\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -0.81\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/06/03\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              220.13\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              2.83\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              1.3\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/05/31\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              217.30\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -3.55\n",
      "             </td>\n",
      "             <td class=\"wfb2rr\">\n",
      "              -1.61\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/05/30\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              220.85\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -4.11\n",
      "             </td>\n",
      "             <td class=\"wfb5rr\">\n",
      "              -1.83\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb2c\">\n",
      "              2024/05/29\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              224.96\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              0.28\n",
      "             </td>\n",
      "             <td class=\"wfb2r\">\n",
      "              0.12\n",
      "             </td>\n",
      "            </tr>\n",
      "            <tr>\n",
      "             <td class=\"wfb5c\">\n",
      "              2024/05/28\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              224.68\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.52\n",
      "             </td>\n",
      "             <td class=\"wfb5r\">\n",
      "              0.23\n",
      "             </td>\n",
      "            </tr>\n",
      "           </table>\n",
      "          </td>\n",
      "         </tr>\n",
      "         <input name=\"as_sfid\" type=\"hidden\" value=\"AAAAAAU-aEY_7LLSztfxzQutuTo_liUeTKi1ShHKKT1uiy8NlROFAUn6ftfbchCwHJJ06MwntMAnJc9_baquu6-DKLcJbXeauHbhVGor_bZqQs4ujZFREeqE-EqqHjLFiT65divnnlojcQ9MycMRGEUJl_vUzeqg247uihqfP0FlobdvMg==\"/>\n",
      "         <input name=\"as_fid\" type=\"hidden\" value=\"6e302690f77c6153619ea65a7f1ac342ebb550a4\"/>\n",
      "        </form>\n",
      "       </table>\n",
      "       <script language=\"JavaScript\">\n",
      "        <!--\n",
      "var sfund_year ='1@1@一年淨值@1@2@1@二年淨值@1@3@1@三年淨值@1@7@1@五年淨值@1@4@1@一個月淨值@1@5@1@三個月淨值@1@6@1@六個月淨值@1@';\n",
      "InitComboList(document.wr02_frm.selYEAR, '', '', '1', sfund_year, '請選擇');\n",
      "function radioSelYear_onclick(a) {\t\t\n",
      "     if (a) {\t\t\t\t\t\t\t\n",
      "\t\t\tdocument.wr02_frm.elements['Y1'].disabled = true;    \n",
      "\t\t\tdocument.wr02_frm.elements['Y2'].disabled = true;    \n",
      "\t\t\tdocument.wr02_frm.elements['M1'].disabled = true;    \n",
      "\t\t\tdocument.wr02_frm.elements['M2'].disabled = true;    \n",
      "\t\t\tdocument.wr02_frm.elements['D1'].disabled = true;    \n",
      "\t\t\tdocument.wr02_frm.elements['D2'].disabled = true;    \n",
      "\t\t\tdocument.wr02_frm.elements['selYEAR'].disabled = false;    \n",
      "     }else{\t\t\t\t\t\t\t\n",
      "\t\t\tdocument.wr02_frm.elements['Y1'].disabled = false;    \n",
      "\t\t\tdocument.wr02_frm.elements['Y2'].disabled = false;    \n",
      "\t\t\tdocument.wr02_frm.elements['M1'].disabled = false;    \n",
      "\t\t\tdocument.wr02_frm.elements['M2'].disabled = false;    \n",
      "\t\t\tdocument.wr02_frm.elements['D1'].disabled = false;    \n",
      "\t\t\tdocument.wr02_frm.elements['D2'].disabled = false;    \n",
      "\t\t\tdocument.wr02_frm.elements['selYEAR'].disabled = true;    \n",
      "\t\t}\t\t\t\t\t\t\t\t\n",
      "}\t\t\t\n",
      "function SelYear_onChange(a,b) {\t\t\n",
      "     if (a) {\t\t\t\t\t\t\t\n",
      "\t\t\tif (b > 0) {\t\t\t\t\t\n",
      "\t\t\t\tdocument.wr02_frm.elements['Y1'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['Y2'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['M1'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['M2'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['D1'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['D2'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['selYEAR'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['radioMonth'][0].checked = true;    \n",
      "\t\t\t}else{\t\t\t\t\t\t\t\n",
      "\t\t\t\tdocument.wr02_frm.elements['Y1'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['Y2'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['M1'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['M2'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['D1'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['D2'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['selYEAR'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['radioMonth'][0].checked = false;    \n",
      "\t\t\t}\t\t\t\t\t\t\t\t\n",
      "     }else{\t\t\t\t\t\t\t\n",
      "\t\t\t\tdocument.wr02_frm.elements['Y1'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['Y2'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['M1'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['M2'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['D1'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['D2'].disabled = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['selYEAR'].disabled = true;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['radioMonth'][0].checked = false;    \n",
      "\t\t\t\tdocument.wr02_frm.elements['radioMonth'][1].checked = true;    \n",
      "\t\t}\t\t\t\t\t\t\t\t\n",
      "}\t\t\t\t\t\t\t\t\t\n",
      "function jumpgo(){ \n",
      "\tvar bcdurl = ''; \n",
      "\tvar mLink='';\n",
      "\tif (document.wr02_frm.elements['radioMonth'][0].checked && document.wr02_frm.elements['selYEAR'].selectedIndex > 0) {\n",
      "\t\tmLink = '_' + document.wr02_frm.elements['selYEAR'].options[document.wr02_frm.elements['selYEAR'].selectedIndex].value + '_0_0';\n",
      "\t}else if (document.wr02_frm.elements['radioMonth'][1].checked) {\n",
      "\t\tvar sTempDate= CheckSubmit() ;\n",
      "\t\tif (sTempDate != 'false')\t\n",
      "\t\t\tmLink = '_0_' + sTempDate;\t\n",
      "\t\telse return;\n",
      "\t}\n",
      "\tif (mLink == '') {\n",
      "\t\talert('請選擇要比較的區間');\n",
      "\t\tdocument.wr02_frm.elements['BB1'].disabled =  false;\n",
      "\t\treturn;\n",
      "\t}\n",
      "\tbcdurl = '/w/wr/wr02_ACPS02-0603' + mLink + '.djhtm';\n",
      "\tself.location = bcdurl ; \n",
      "} \n",
      "// -->\n",
      "       </script>\n",
      "      </td>\n",
      "     </tr>\n",
      "     <tr>\n",
      "      <td>\n",
      "      </td>\n",
      "     </tr>\n",
      "    </table>\n",
      "   </div>\n",
      "   <script language=\"javascript\" src=\"/w/js/SD.js\">\n",
      "   </script>\n",
      "  </center>\n",
      "  <script language=\"javascript\" src=\"/w/js/CelebrusInsertJS.djjs\">\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from tqdm import tqdm\n",
    "import chardet\n",
    "\n",
    "with open('uniblack_stocks/uni_hor.html', 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    result = chardet.detect(raw_data)\n",
    "    encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "# 使用檢測到的編碼讀取文件\n",
    "with open('uniblack_stocks/uni_hor.html', encoding=encoding) as html_file:\n",
    "    html_content = html_file.read()\n",
    "\n",
    "\n",
    "# 使用 BeautifulSoup 解析 HTML 文件的內容\n",
    "objSoup = bs4.BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "# 將解析後的結果轉換為字符串並按行分割\n",
    "pretty_html = objSoup.prettify().split('\\n')\n",
    "\n",
    "# 使用 tqdm 顯示進度條逐行打印解析後的結果\n",
    "for line in tqdm(pretty_html, desc=\"Printing HTML\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料:\n",
      "     index        date     volume         amount      open      high  \\\n",
      "0        1  2023/01/04  6,156,121  5,333,596,225    850.00    882.00   \n",
      "1        2  2023/01/05  6,189,016  5,410,239,243    888.00    897.00   \n",
      "2        3  2023/01/06  4,465,787  3,800,656,142    860.00    868.00   \n",
      "3        4  2023/01/09  5,261,930  4,521,987,667    859.00    873.00   \n",
      "4        5  2023/01/10  3,226,082  2,751,787,931    859.00    868.00   \n",
      "..     ...         ...        ...            ...       ...       ...   \n",
      "355      0  2024/07/01  1,843,413  4,573,201,995  2,470.00  2,510.00   \n",
      "356      1  2024/07/02  1,641,346  4,051,285,435  2,470.00  2,510.00   \n",
      "357      2  2024/07/03  2,216,019  5,476,201,385  2,485.00  2,535.00   \n",
      "358      3  2024/07/04  3,030,115  7,728,894,730  2,495.00  2,620.00   \n",
      "359      4  2024/07/05  2,928,024  7,463,372,970  2,615.00  2,625.00   \n",
      "\n",
      "          low     close   change transactions  \n",
      "0      844.00    879.00   +24.00        6,328  \n",
      "1      851.00    857.00   -22.00        9,301  \n",
      "2      831.00    837.00   -20.00        5,072  \n",
      "3      849.00    854.00   +17.00        5,159  \n",
      "4      836.00    851.00    -3.00        3,558  \n",
      "..        ...       ...      ...          ...  \n",
      "355  2,425.00  2,495.00   +40.00        6,157  \n",
      "356  2,445.00  2,455.00   -40.00        7,406  \n",
      "357  2,440.00  2,470.00   +15.00        7,339  \n",
      "358  2,485.00  2,615.00  +145.00       10,481  \n",
      "359  2,510.00  2,525.00   -90.00       14,219  \n",
      "\n",
      "[360 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'uniblack_stocks/3661世芯-KY.csv'\n",
    "\n",
    "# 讀取CSV檔案\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 新的列名\n",
    "new_columns = ['index', 'date', 'volume', 'amount', 'open', 'high', 'low', 'close', 'change', 'transactions']\n",
    "\n",
    "# 修改資料框的列名\n",
    "data.columns = new_columns\n",
    "\n",
    "print(\"原始資料:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       volume    amount      open      high       low     close  transactions\n",
      "0    1.635717 -0.500859 -1.652797 -1.649647 -1.642413 -1.630389      0.016670\n",
      "1    1.654212 -0.475771 -1.612918 -1.634112 -1.634848 -1.653806      0.789501\n",
      "2    0.685348 -1.002634 -1.642302 -1.664145 -1.656460 -1.675094     -0.309827\n",
      "3    1.132969 -0.766521 -1.643352 -1.658967 -1.637010 -1.656999     -0.287211\n",
      "4   -0.011661 -1.345958 -1.643352 -1.664145 -1.651057 -1.660192     -0.703391\n",
      "..        ...       ...       ...       ...       ...       ...           ...\n",
      "355 -0.789050 -0.749757  0.047316  0.036353  0.065994  0.089679     -0.027781\n",
      "356 -0.902659 -0.920596  0.047316  0.036353  0.087606  0.047103      0.296896\n",
      "357 -0.579557 -0.454180  0.063057  0.062244  0.082203  0.063069      0.279479\n",
      "358 -0.121841  0.283191  0.073552  0.150272  0.130829  0.217406      1.096242\n",
      "359 -0.179241  0.196278  0.199486  0.155450  0.157844  0.121610      2.067934\n",
      "\n",
      "[360 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 假設 data 已經被讀取進來\n",
    "# 排除不需要的欄位\n",
    "columns_to_exclude = ['index', 'date', 'change']\n",
    "data_to_normalize = data.drop(columns=columns_to_exclude)\n",
    "\n",
    "# 確保要標準化的欄位是數值型別，移除千分位逗號並轉換為 float\n",
    "for column in ['volume', 'amount', 'transactions']:\n",
    "    data_to_normalize[column] = data_to_normalize[column].str.replace(',', '').astype(float)\n",
    "\n",
    "# 轉換剩餘的欄位為 float 型別\n",
    "for column in ['open', 'high', 'low', 'close']:\n",
    "    data_to_normalize[column] = data_to_normalize[column].str.replace(',', '').astype(float)\n",
    "\n",
    "# 標準化處理\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "# 轉換為 DataFrame\n",
    "clean_data = pd.DataFrame(normalized_data, columns=data_to_normalize.columns)\n",
    "\n",
    "# 顯示結果\n",
    "print(clean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           日期      淨值    漲/跌 漲跌幅(%)\n",
      "0   2024/07/09  236.31   1.76   0.75\n",
      "1   2024/07/08  234.55  -0.56  -0.24\n",
      "2   2024/07/05  235.11   3.01    1.3\n",
      "3   2024/07/04  232.10   4.32    1.9\n",
      "4   2024/07/03  227.78   2.17   0.96\n",
      "5   2024/07/02  225.61  -0.85  -0.38\n",
      "6   2024/07/01  226.46  -2.45  -1.07\n",
      "7   2024/06/28  228.91   3.19   1.41\n",
      "8   2024/06/27  225.72  -0.96  -0.42\n",
      "9   2024/06/26  226.68   4.15   1.86\n",
      "10  2024/06/25  222.53   0.17   0.08\n",
      "11  2024/06/24  222.36  -5.42  -2.38\n",
      "12  2024/06/21  227.78  -2.67  -1.16\n",
      "13  2024/06/20  230.45   3.81   1.68\n",
      "14  2024/06/19  226.64   1.53   0.68\n",
      "15  2024/06/18  225.11  -0.51  -0.23\n",
      "16  2024/06/17  225.62  -0.83  -0.37\n",
      "17  2024/06/14  226.45   2.86   1.28\n",
      "18  2024/06/13  223.59   2.26   1.02\n",
      "19  2024/06/12  221.33   3.53   1.62\n",
      "20  2024/06/11  217.80  -0.27  -0.12\n",
      "21  2024/06/07  218.07  -0.84  -0.38\n",
      "22  2024/06/06  218.91   0.72   0.33\n",
      "23  2024/06/05  218.19  -0.16  -0.07\n",
      "24  2024/06/04  218.35  -1.78  -0.81\n",
      "25  2024/06/03  220.13   2.83    1.3\n",
      "26  2024/05/31  217.30  -3.55  -1.61\n",
      "27  2024/05/30  220.85  -4.11  -1.83\n",
      "28  2024/05/29  224.96   0.28   0.12\n",
      "29  2024/05/28  224.68   0.52   0.23\n"
     ]
    }
   ],
   "source": [
    "aa=pd.read_html('uniblack_stocks/uni_hor.html')\n",
    "\n",
    "df_a=aa[2]\n",
    "df_b=aa[3]\n",
    "\n",
    "# 移除表格 A 和 B 的第一行（標題行）進行上下合併\n",
    "df_a_content = df_a.iloc[1:].reset_index(drop=True)\n",
    "df_b_content = df_b.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# 合併表格\n",
    "combined_df = pd.concat([df_a_content, df_b_content], ignore_index=True)\n",
    "\n",
    "# 設置標題行\n",
    "combined_df.columns = df_a.iloc[0]\n",
    "\n",
    "# 顯示合併後的 DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       volume    amount      open      high       low     close  transactions\n",
      "349  0.192450  0.936533  0.377893  0.362576  0.319931  0.286592      2.453180\n",
      "350 -0.741655 -0.572503  0.251959  0.238301  0.255096  0.201440      1.987610\n",
      "351 -0.466068 -0.216241  0.183744  0.139916  0.179455  0.174830      1.921583\n",
      "352 -0.078908  0.339435  0.204734  0.155450  0.163247  0.121610      2.921090\n",
      "353  0.889733  1.622960  0.068305  0.036353  0.049785  0.041781      5.232824\n",
      "354 -0.684105 -0.613598  0.026327  0.020819  0.082203  0.047103      0.398536\n",
      "355 -0.789050 -0.749757  0.047316  0.036353  0.065994  0.089679     -0.027781\n",
      "356 -0.902659 -0.920596  0.047316  0.036353  0.087606  0.047103      0.296896\n",
      "357 -0.579557 -0.454180  0.063057  0.062244  0.082203  0.063069      0.279479\n",
      "358 -0.121841  0.283191  0.073552  0.150272  0.130829  0.217406      1.096242\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "needed_data=clean_data[-30:-1]\n",
    "\n",
    "# 生成滑動窗口的資料組\n",
    "train_data_x = [needed_data.iloc[i:i+10] for i in range(len(needed_data) - 9)]\n",
    "\n",
    "'''\n",
    "# 列印每組資料\n",
    "for i, group in enumerate(train_data_x):\n",
    "    print(f\"Group {i+1}:\\n{group}\\n\")\n",
    "'''\n",
    "\n",
    "print(train_data_x[19])\n",
    "print(len(train_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    淨值\n",
      "0   100\n",
      "1    90\n",
      "2    93\n",
      "3    77\n",
      "4    55\n",
      "5    43\n",
      "6    48\n",
      "7    61\n",
      "8    44\n",
      "9    49\n",
      "10   27\n",
      "11   26\n",
      "12   55\n",
      "13   69\n",
      "14   49\n",
      "15   41\n",
      "16   43\n",
      "17   48\n",
      "18   33\n",
      "19   21\n",
      "20    2\n",
      "21    4\n",
      "22    8\n",
      "23    4\n",
      "24    5\n",
      "25   14\n",
      "26    0\n",
      "27   18\n",
      "28   40\n",
      "29   38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 使用 MinMaxScaler 進行標準化\n",
    "scaler = MinMaxScaler()\n",
    "combined_df['淨值'] = scaler.fit_transform(combined_df[['淨值']])\n",
    "\n",
    "# 將標準化後的 '淨值' 欄位乘以 100 並轉換為整數\n",
    "combined_df['淨值'] = (combined_df['淨值'] * 100).astype(int)\n",
    "\n",
    "# 只保留 '淨值' 欄位，並且去除 '日期', '漲/跌', '漲跌幅(%)' 欄位\n",
    "data_y = combined_df[['淨值']]\n",
    "\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_y_now: [38, 40, 18, 0, 14, 5, 4, 8, 4, 2, 21, 33, 48, 43, 41, 49, 69, 55, 26, 27]\n",
      "data_y_future: [21, 33, 48, 43, 41, 49, 69, 55, 26, 27, 49, 44, 61, 48, 43, 55, 77, 93, 90, 100]\n"
     ]
    }
   ],
   "source": [
    "# 提取所需的值\n",
    "data_y_now=[]\n",
    "data_y_future=[]\n",
    "\n",
    "for i in range(29,9,-1):\n",
    "    data_y_now.append(data_y['淨值'].iloc[i])\n",
    "    data_y_future.append(data_y['淨值'].iloc[i-10])\n",
    "\n",
    "print(f\"data_y_now: {data_y_now}\")\n",
    "print(f\"data_y_future: {data_y_future}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_y_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_label=[]\n",
    "\n",
    "for i in range(len(data_y_future)):\n",
    "    if data_y_now[i]>=data_y_future[i]:\n",
    "        y_label.append(0)   #不要進場\n",
    "    else:\n",
    "        y_label.append(1)   #進場\n",
    "\n",
    "print(train_data_x[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = tts(train_data_x, y_label, test_size = 0.2,random_state=7100) #test_size可改\n",
    "x_valid, x_test, y_valid, y_test = tts(x_temp, y_temp, test_size = 0.5,random_state=7100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 定義 TCN 模型\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TCN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(192, 128)\n",
    "        self.fc2 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 示例輸入形狀 (batch_size, input_size, sequence_length)\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "\n",
    "model = TCN(input_size, output_size)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross entropy with logits for one-hot encoded targets\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设类别数量为2\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "# 将标签转换为 Tensor 类型\n",
    "y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# 将标签转换为 one-hot 编码\n",
    "y_valid_one_hot = F.one_hot(y_valid_tensor, num_classes)\n",
    "y_train_one_hot = F.one_hot(y_train_tensor, num_classes)\n",
    "\n",
    "print(y_valid_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除 index 和欄位名稱\n",
    "\n",
    "# 將每個 DataFrame 轉換為 numpy array 然後轉換為 tensor\n",
    "x_train_tensors = [torch.tensor(df.values, dtype=torch.float32) for df in x_train]\n",
    "x_valid_tensors = [torch.tensor(df.values, dtype=torch.float32) for df in x_valid]\n",
    "x_test_tensors = [torch.tensor(df.values, dtype=torch.float32) for df in x_test]\n",
    "\n",
    "# 合併所有 tensor 成為一個大的 tensor（如果需要）\n",
    "x_train_tensor = torch.stack(x_train_tensors)\n",
    "x_valid_tensor = torch.stack(x_valid_tensors)\n",
    "x_test_tensor = torch.stack(x_test_tensors)\n",
    "\n",
    "#y_train_tensor = torch.LongTensor(y_train)\n",
    "#y_valid_tensor = torch.LongTensor(y_valid)\n",
    "\n",
    "# 創建 DataLoader\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_one_hot)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# 創建 DataLoader\n",
    "valid_dataset = TensorDataset(x_valid_tensor, y_valid_one_hot)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Train Loss: 0.64777848, Validation Loss: 0.59302706, Accuracy: 1.0000\n",
      "Epoch 2/1000, Train Loss: 0.58046660, Validation Loss: 0.48402493, Accuracy: 1.0000\n",
      "Epoch 3/1000, Train Loss: 0.50401909, Validation Loss: 0.38571577, Accuracy: 1.0000\n",
      "Epoch 4/1000, Train Loss: 0.43058169, Validation Loss: 0.31112990, Accuracy: 1.0000\n",
      "Epoch 5/1000, Train Loss: 0.38277983, Validation Loss: 0.21986410, Accuracy: 1.0000\n",
      "Epoch 6/1000, Train Loss: 0.34103275, Validation Loss: 0.18123560, Accuracy: 1.0000\n",
      "Epoch 7/1000, Train Loss: 0.31666004, Validation Loss: 0.14509260, Accuracy: 1.0000\n",
      "Epoch 8/1000, Train Loss: 0.30308020, Validation Loss: 0.12235502, Accuracy: 1.0000\n",
      "Epoch 9/1000, Train Loss: 0.28640549, Validation Loss: 0.11253177, Accuracy: 1.0000\n",
      "Epoch 10/1000, Train Loss: 0.26812540, Validation Loss: 0.10559167, Accuracy: 1.0000\n",
      "Epoch 11/1000, Train Loss: 0.25215470, Validation Loss: 0.10012814, Accuracy: 1.0000\n",
      "Epoch 12/1000, Train Loss: 0.23927913, Validation Loss: 0.09618430, Accuracy: 1.0000\n",
      "Epoch 13/1000, Train Loss: 0.22250697, Validation Loss: 0.09125514, Accuracy: 1.0000\n",
      "Epoch 14/1000, Train Loss: 0.20636501, Validation Loss: 0.07572251, Accuracy: 1.0000\n",
      "Epoch 15/1000, Train Loss: 0.18471845, Validation Loss: 0.07164732, Accuracy: 1.0000\n",
      "Epoch 16/1000, Train Loss: 0.17210883, Validation Loss: 0.07094688, Accuracy: 1.0000\n",
      "Epoch 17/1000, Train Loss: 0.15014674, Validation Loss: 0.05844094, Accuracy: 1.0000\n",
      "Epoch 18/1000, Train Loss: 0.13495005, Validation Loss: 0.04681173, Accuracy: 1.0000\n",
      "Epoch 19/1000, Train Loss: 0.11722210, Validation Loss: 0.04215210, Accuracy: 1.0000\n",
      "Epoch 20/1000, Train Loss: 0.10330768, Validation Loss: 0.03759739, Accuracy: 1.0000\n",
      "Epoch 21/1000, Train Loss: 0.08996123, Validation Loss: 0.03197748, Accuracy: 1.0000\n",
      "Epoch 22/1000, Train Loss: 0.07807576, Validation Loss: 0.02618923, Accuracy: 1.0000\n",
      "Epoch 23/1000, Train Loss: 0.06900719, Validation Loss: 0.02322769, Accuracy: 1.0000\n",
      "Epoch 24/1000, Train Loss: 0.05897419, Validation Loss: 0.01781735, Accuracy: 1.0000\n",
      "Epoch 25/1000, Train Loss: 0.05149786, Validation Loss: 0.01564897, Accuracy: 1.0000\n",
      "Epoch 26/1000, Train Loss: 0.04527889, Validation Loss: 0.01344566, Accuracy: 1.0000\n",
      "Epoch 27/1000, Train Loss: 0.04045395, Validation Loss: 0.01205290, Accuracy: 1.0000\n",
      "Epoch 28/1000, Train Loss: 0.03450982, Validation Loss: 0.00954205, Accuracy: 1.0000\n",
      "Epoch 29/1000, Train Loss: 0.03041609, Validation Loss: 0.00830533, Accuracy: 1.0000\n",
      "Epoch 30/1000, Train Loss: 0.02686861, Validation Loss: 0.00732847, Accuracy: 1.0000\n",
      "Epoch 31/1000, Train Loss: 0.02419749, Validation Loss: 0.00617973, Accuracy: 1.0000\n",
      "Epoch 32/1000, Train Loss: 0.02130411, Validation Loss: 0.00526995, Accuracy: 1.0000\n",
      "Epoch 33/1000, Train Loss: 0.01911504, Validation Loss: 0.00476875, Accuracy: 1.0000\n",
      "Epoch 34/1000, Train Loss: 0.01740138, Validation Loss: 0.00434287, Accuracy: 1.0000\n",
      "Epoch 35/1000, Train Loss: 0.01560600, Validation Loss: 0.00372117, Accuracy: 1.0000\n",
      "Epoch 36/1000, Train Loss: 0.01416747, Validation Loss: 0.00321631, Accuracy: 1.0000\n",
      "Epoch 37/1000, Train Loss: 0.01312922, Validation Loss: 0.00309910, Accuracy: 1.0000\n",
      "Epoch 38/1000, Train Loss: 0.01174041, Validation Loss: 0.00276440, Accuracy: 1.0000\n",
      "Epoch 39/1000, Train Loss: 0.01081696, Validation Loss: 0.00248446, Accuracy: 1.0000\n",
      "Epoch 40/1000, Train Loss: 0.00974055, Validation Loss: 0.00224574, Accuracy: 1.0000\n",
      "Epoch 41/1000, Train Loss: 0.00903624, Validation Loss: 0.00201600, Accuracy: 1.0000\n",
      "Epoch 42/1000, Train Loss: 0.00837729, Validation Loss: 0.00187553, Accuracy: 1.0000\n",
      "Epoch 43/1000, Train Loss: 0.00774304, Validation Loss: 0.00170182, Accuracy: 1.0000\n",
      "Epoch 44/1000, Train Loss: 0.00719548, Validation Loss: 0.00156894, Accuracy: 1.0000\n",
      "Epoch 45/1000, Train Loss: 0.00665065, Validation Loss: 0.00142218, Accuracy: 1.0000\n",
      "Epoch 46/1000, Train Loss: 0.00616158, Validation Loss: 0.00131575, Accuracy: 1.0000\n",
      "Epoch 47/1000, Train Loss: 0.00587595, Validation Loss: 0.00123145, Accuracy: 1.0000\n",
      "Epoch 48/1000, Train Loss: 0.00542119, Validation Loss: 0.00113058, Accuracy: 1.0000\n",
      "Epoch 49/1000, Train Loss: 0.00508832, Validation Loss: 0.00108200, Accuracy: 1.0000\n",
      "Epoch 50/1000, Train Loss: 0.00475136, Validation Loss: 0.00099194, Accuracy: 1.0000\n",
      "Epoch 51/1000, Train Loss: 0.00447472, Validation Loss: 0.00090624, Accuracy: 1.0000\n",
      "Epoch 52/1000, Train Loss: 0.00420544, Validation Loss: 0.00087505, Accuracy: 1.0000\n",
      "Epoch 53/1000, Train Loss: 0.00397553, Validation Loss: 0.00082053, Accuracy: 1.0000\n",
      "Epoch 54/1000, Train Loss: 0.00375854, Validation Loss: 0.00075909, Accuracy: 1.0000\n",
      "Epoch 55/1000, Train Loss: 0.00357296, Validation Loss: 0.00072647, Accuracy: 1.0000\n",
      "Epoch 56/1000, Train Loss: 0.00334685, Validation Loss: 0.00067438, Accuracy: 1.0000\n",
      "Epoch 57/1000, Train Loss: 0.00319467, Validation Loss: 0.00063871, Accuracy: 1.0000\n",
      "Epoch 58/1000, Train Loss: 0.00302742, Validation Loss: 0.00059888, Accuracy: 1.0000\n",
      "Epoch 59/1000, Train Loss: 0.00288787, Validation Loss: 0.00057482, Accuracy: 1.0000\n",
      "Epoch 60/1000, Train Loss: 0.00272657, Validation Loss: 0.00054189, Accuracy: 1.0000\n",
      "Epoch 61/1000, Train Loss: 0.00260796, Validation Loss: 0.00051163, Accuracy: 1.0000\n",
      "Epoch 62/1000, Train Loss: 0.00250533, Validation Loss: 0.00049296, Accuracy: 1.0000\n",
      "Epoch 63/1000, Train Loss: 0.00237085, Validation Loss: 0.00046065, Accuracy: 1.0000\n",
      "Epoch 64/1000, Train Loss: 0.00229110, Validation Loss: 0.00044279, Accuracy: 1.0000\n",
      "Epoch 65/1000, Train Loss: 0.00217034, Validation Loss: 0.00042387, Accuracy: 1.0000\n",
      "Epoch 66/1000, Train Loss: 0.00207099, Validation Loss: 0.00040285, Accuracy: 1.0000\n",
      "Epoch 67/1000, Train Loss: 0.00199571, Validation Loss: 0.00038018, Accuracy: 1.0000\n",
      "Epoch 68/1000, Train Loss: 0.00190508, Validation Loss: 0.00036538, Accuracy: 1.0000\n",
      "Epoch 69/1000, Train Loss: 0.00182664, Validation Loss: 0.00035365, Accuracy: 1.0000\n",
      "Epoch 70/1000, Train Loss: 0.00174846, Validation Loss: 0.00033515, Accuracy: 1.0000\n",
      "Epoch 71/1000, Train Loss: 0.00169164, Validation Loss: 0.00032044, Accuracy: 1.0000\n",
      "Epoch 72/1000, Train Loss: 0.00162065, Validation Loss: 0.00030498, Accuracy: 1.0000\n",
      "Epoch 73/1000, Train Loss: 0.00155556, Validation Loss: 0.00029497, Accuracy: 1.0000\n",
      "Epoch 74/1000, Train Loss: 0.00151123, Validation Loss: 0.00028270, Accuracy: 1.0000\n",
      "Epoch 75/1000, Train Loss: 0.00143866, Validation Loss: 0.00027164, Accuracy: 1.0000\n",
      "Epoch 76/1000, Train Loss: 0.00138769, Validation Loss: 0.00026274, Accuracy: 1.0000\n",
      "Epoch 77/1000, Train Loss: 0.00136309, Validation Loss: 0.00025431, Accuracy: 1.0000\n",
      "Epoch 78/1000, Train Loss: 0.00128848, Validation Loss: 0.00024191, Accuracy: 1.0000\n",
      "Epoch 79/1000, Train Loss: 0.00124935, Validation Loss: 0.00023491, Accuracy: 1.0000\n",
      "Epoch 80/1000, Train Loss: 0.00120977, Validation Loss: 0.00022758, Accuracy: 1.0000\n",
      "Epoch 81/1000, Train Loss: 0.00115878, Validation Loss: 0.00021683, Accuracy: 1.0000\n",
      "Epoch 82/1000, Train Loss: 0.00112225, Validation Loss: 0.00020894, Accuracy: 1.0000\n",
      "Epoch 83/1000, Train Loss: 0.00108776, Validation Loss: 0.00020080, Accuracy: 1.0000\n",
      "Epoch 84/1000, Train Loss: 0.00105104, Validation Loss: 0.00019508, Accuracy: 1.0000\n",
      "Epoch 85/1000, Train Loss: 0.00102323, Validation Loss: 0.00018975, Accuracy: 1.0000\n",
      "Epoch 86/1000, Train Loss: 0.00098134, Validation Loss: 0.00018096, Accuracy: 1.0000\n",
      "Epoch 87/1000, Train Loss: 0.00095181, Validation Loss: 0.00017536, Accuracy: 1.0000\n",
      "Epoch 88/1000, Train Loss: 0.00092435, Validation Loss: 0.00017041, Accuracy: 1.0000\n",
      "Epoch 89/1000, Train Loss: 0.00089436, Validation Loss: 0.00016350, Accuracy: 1.0000\n",
      "Epoch 90/1000, Train Loss: 0.00087130, Validation Loss: 0.00015948, Accuracy: 1.0000\n",
      "Epoch 91/1000, Train Loss: 0.00084133, Validation Loss: 0.00015474, Accuracy: 1.0000\n",
      "Epoch 92/1000, Train Loss: 0.00081725, Validation Loss: 0.00015054, Accuracy: 1.0000\n",
      "Epoch 93/1000, Train Loss: 0.00079523, Validation Loss: 0.00014470, Accuracy: 1.0000\n",
      "Epoch 94/1000, Train Loss: 0.00077290, Validation Loss: 0.00014068, Accuracy: 1.0000\n",
      "Epoch 95/1000, Train Loss: 0.00074691, Validation Loss: 0.00013547, Accuracy: 1.0000\n",
      "Epoch 96/1000, Train Loss: 0.00072543, Validation Loss: 0.00013198, Accuracy: 1.0000\n",
      "Epoch 97/1000, Train Loss: 0.00070991, Validation Loss: 0.00012825, Accuracy: 1.0000\n",
      "Epoch 98/1000, Train Loss: 0.00068360, Validation Loss: 0.00012483, Accuracy: 1.0000\n",
      "Epoch 99/1000, Train Loss: 0.00066669, Validation Loss: 0.00012110, Accuracy: 1.0000\n",
      "Epoch 100/1000, Train Loss: 0.00064907, Validation Loss: 0.00011723, Accuracy: 1.0000\n",
      "Epoch 101/1000, Train Loss: 0.00063373, Validation Loss: 0.00011416, Accuracy: 1.0000\n",
      "Epoch 102/1000, Train Loss: 0.00061421, Validation Loss: 0.00011062, Accuracy: 1.0000\n",
      "Epoch 103/1000, Train Loss: 0.00059798, Validation Loss: 0.00010781, Accuracy: 1.0000\n",
      "Epoch 104/1000, Train Loss: 0.00058299, Validation Loss: 0.00010513, Accuracy: 1.0000\n",
      "Epoch 105/1000, Train Loss: 0.00056704, Validation Loss: 0.00010156, Accuracy: 1.0000\n",
      "Epoch 106/1000, Train Loss: 0.00055353, Validation Loss: 0.00009956, Accuracy: 1.0000\n",
      "Epoch 107/1000, Train Loss: 0.00054002, Validation Loss: 0.00009631, Accuracy: 1.0000\n",
      "Epoch 108/1000, Train Loss: 0.00052491, Validation Loss: 0.00009444, Accuracy: 1.0000\n",
      "Epoch 109/1000, Train Loss: 0.00051163, Validation Loss: 0.00009143, Accuracy: 1.0000\n",
      "Epoch 110/1000, Train Loss: 0.00050266, Validation Loss: 0.00008919, Accuracy: 1.0000\n",
      "Epoch 111/1000, Train Loss: 0.00048788, Validation Loss: 0.00008740, Accuracy: 1.0000\n",
      "Epoch 112/1000, Train Loss: 0.00047576, Validation Loss: 0.00008496, Accuracy: 1.0000\n",
      "Epoch 113/1000, Train Loss: 0.00046290, Validation Loss: 0.00008252, Accuracy: 1.0000\n",
      "Epoch 114/1000, Train Loss: 0.00045318, Validation Loss: 0.00008100, Accuracy: 1.0000\n",
      "Epoch 115/1000, Train Loss: 0.00044518, Validation Loss: 0.00007805, Accuracy: 1.0000\n",
      "Epoch 116/1000, Train Loss: 0.00043208, Validation Loss: 0.00007745, Accuracy: 1.0000\n",
      "Epoch 117/1000, Train Loss: 0.00042218, Validation Loss: 0.00007459, Accuracy: 1.0000\n",
      "Epoch 118/1000, Train Loss: 0.00041221, Validation Loss: 0.00007247, Accuracy: 1.0000\n",
      "Epoch 119/1000, Train Loss: 0.00040313, Validation Loss: 0.00007191, Accuracy: 1.0000\n",
      "Epoch 120/1000, Train Loss: 0.00039418, Validation Loss: 0.00007006, Accuracy: 1.0000\n",
      "Epoch 121/1000, Train Loss: 0.00038474, Validation Loss: 0.00006780, Accuracy: 1.0000\n",
      "Epoch 122/1000, Train Loss: 0.00037495, Validation Loss: 0.00006595, Accuracy: 1.0000\n",
      "Epoch 123/1000, Train Loss: 0.00036686, Validation Loss: 0.00006473, Accuracy: 1.0000\n",
      "Epoch 124/1000, Train Loss: 0.00035894, Validation Loss: 0.00006353, Accuracy: 1.0000\n",
      "Epoch 125/1000, Train Loss: 0.00035159, Validation Loss: 0.00006181, Accuracy: 1.0000\n",
      "Epoch 126/1000, Train Loss: 0.00034341, Validation Loss: 0.00006035, Accuracy: 1.0000\n",
      "Epoch 127/1000, Train Loss: 0.00033679, Validation Loss: 0.00005933, Accuracy: 1.0000\n",
      "Epoch 128/1000, Train Loss: 0.00032897, Validation Loss: 0.00005781, Accuracy: 1.0000\n",
      "Epoch 129/1000, Train Loss: 0.00032254, Validation Loss: 0.00005641, Accuracy: 1.0000\n",
      "Epoch 130/1000, Train Loss: 0.00031480, Validation Loss: 0.00005555, Accuracy: 1.0000\n",
      "Epoch 131/1000, Train Loss: 0.00030941, Validation Loss: 0.00005424, Accuracy: 1.0000\n",
      "Epoch 132/1000, Train Loss: 0.00030173, Validation Loss: 0.00005284, Accuracy: 1.0000\n",
      "Epoch 133/1000, Train Loss: 0.00029586, Validation Loss: 0.00005167, Accuracy: 1.0000\n",
      "Epoch 134/1000, Train Loss: 0.00029045, Validation Loss: 0.00005087, Accuracy: 1.0000\n",
      "Epoch 135/1000, Train Loss: 0.00028396, Validation Loss: 0.00004950, Accuracy: 1.0000\n",
      "Epoch 136/1000, Train Loss: 0.00027849, Validation Loss: 0.00004858, Accuracy: 1.0000\n",
      "Epoch 137/1000, Train Loss: 0.00027218, Validation Loss: 0.00004729, Accuracy: 1.0000\n",
      "Epoch 138/1000, Train Loss: 0.00026736, Validation Loss: 0.00004634, Accuracy: 1.0000\n",
      "Epoch 139/1000, Train Loss: 0.00026138, Validation Loss: 0.00004557, Accuracy: 1.0000\n",
      "Epoch 140/1000, Train Loss: 0.00025654, Validation Loss: 0.00004467, Accuracy: 1.0000\n",
      "Epoch 141/1000, Train Loss: 0.00025233, Validation Loss: 0.00004369, Accuracy: 1.0000\n",
      "Epoch 142/1000, Train Loss: 0.00024646, Validation Loss: 0.00004273, Accuracy: 1.0000\n",
      "Epoch 143/1000, Train Loss: 0.00024162, Validation Loss: 0.00004187, Accuracy: 1.0000\n",
      "Epoch 144/1000, Train Loss: 0.00023717, Validation Loss: 0.00004101, Accuracy: 1.0000\n",
      "Epoch 145/1000, Train Loss: 0.00023400, Validation Loss: 0.00004005, Accuracy: 1.0000\n",
      "Epoch 146/1000, Train Loss: 0.00022755, Validation Loss: 0.00003937, Accuracy: 1.0000\n",
      "Epoch 147/1000, Train Loss: 0.00022365, Validation Loss: 0.00003859, Accuracy: 1.0000\n",
      "Epoch 148/1000, Train Loss: 0.00021913, Validation Loss: 0.00003791, Accuracy: 1.0000\n",
      "Epoch 149/1000, Train Loss: 0.00021529, Validation Loss: 0.00003698, Accuracy: 1.0000\n",
      "Epoch 150/1000, Train Loss: 0.00021178, Validation Loss: 0.00003642, Accuracy: 1.0000\n",
      "Epoch 151/1000, Train Loss: 0.00020730, Validation Loss: 0.00003570, Accuracy: 1.0000\n",
      "Epoch 152/1000, Train Loss: 0.00020397, Validation Loss: 0.00003499, Accuracy: 1.0000\n",
      "Epoch 153/1000, Train Loss: 0.00019950, Validation Loss: 0.00003427, Accuracy: 1.0000\n",
      "Epoch 154/1000, Train Loss: 0.00019749, Validation Loss: 0.00003329, Accuracy: 1.0000\n",
      "Epoch 155/1000, Train Loss: 0.00019248, Validation Loss: 0.00003305, Accuracy: 1.0000\n",
      "Epoch 156/1000, Train Loss: 0.00018981, Validation Loss: 0.00003248, Accuracy: 1.0000\n",
      "Epoch 157/1000, Train Loss: 0.00018547, Validation Loss: 0.00003183, Accuracy: 1.0000\n",
      "Epoch 158/1000, Train Loss: 0.00018266, Validation Loss: 0.00003123, Accuracy: 1.0000\n",
      "Epoch 159/1000, Train Loss: 0.00017889, Validation Loss: 0.00003052, Accuracy: 1.0000\n",
      "Epoch 160/1000, Train Loss: 0.00017595, Validation Loss: 0.00003010, Accuracy: 1.0000\n",
      "Epoch 161/1000, Train Loss: 0.00017257, Validation Loss: 0.00002938, Accuracy: 1.0000\n",
      "Epoch 162/1000, Train Loss: 0.00017020, Validation Loss: 0.00002903, Accuracy: 1.0000\n",
      "Epoch 163/1000, Train Loss: 0.00016723, Validation Loss: 0.00002828, Accuracy: 1.0000\n",
      "Epoch 164/1000, Train Loss: 0.00016408, Validation Loss: 0.00002786, Accuracy: 1.0000\n",
      "Epoch 165/1000, Train Loss: 0.00016129, Validation Loss: 0.00002730, Accuracy: 1.0000\n",
      "Epoch 166/1000, Train Loss: 0.00015855, Validation Loss: 0.00002685, Accuracy: 1.0000\n",
      "Epoch 167/1000, Train Loss: 0.00015523, Validation Loss: 0.00002643, Accuracy: 1.0000\n",
      "Epoch 168/1000, Train Loss: 0.00015332, Validation Loss: 0.00002596, Accuracy: 1.0000\n",
      "Epoch 169/1000, Train Loss: 0.00015042, Validation Loss: 0.00002554, Accuracy: 1.0000\n",
      "Epoch 170/1000, Train Loss: 0.00014773, Validation Loss: 0.00002497, Accuracy: 1.0000\n",
      "Epoch 171/1000, Train Loss: 0.00014506, Validation Loss: 0.00002450, Accuracy: 1.0000\n",
      "Epoch 172/1000, Train Loss: 0.00014289, Validation Loss: 0.00002411, Accuracy: 1.0000\n",
      "Epoch 173/1000, Train Loss: 0.00014037, Validation Loss: 0.00002366, Accuracy: 1.0000\n",
      "Epoch 174/1000, Train Loss: 0.00013830, Validation Loss: 0.00002325, Accuracy: 1.0000\n",
      "Epoch 175/1000, Train Loss: 0.00013611, Validation Loss: 0.00002289, Accuracy: 1.0000\n",
      "Epoch 176/1000, Train Loss: 0.00013373, Validation Loss: 0.00002250, Accuracy: 1.0000\n",
      "Epoch 177/1000, Train Loss: 0.00013157, Validation Loss: 0.00002208, Accuracy: 1.0000\n",
      "Epoch 178/1000, Train Loss: 0.00012925, Validation Loss: 0.00002181, Accuracy: 1.0000\n",
      "Epoch 179/1000, Train Loss: 0.00012697, Validation Loss: 0.00002137, Accuracy: 1.0000\n",
      "Epoch 180/1000, Train Loss: 0.00012535, Validation Loss: 0.00002092, Accuracy: 1.0000\n",
      "Epoch 181/1000, Train Loss: 0.00012304, Validation Loss: 0.00002059, Accuracy: 1.0000\n",
      "Epoch 182/1000, Train Loss: 0.00012099, Validation Loss: 0.00002021, Accuracy: 1.0000\n",
      "Epoch 183/1000, Train Loss: 0.00011909, Validation Loss: 0.00001991, Accuracy: 1.0000\n",
      "Epoch 184/1000, Train Loss: 0.00011714, Validation Loss: 0.00001961, Accuracy: 1.0000\n",
      "Epoch 185/1000, Train Loss: 0.00011550, Validation Loss: 0.00001925, Accuracy: 1.0000\n",
      "Epoch 186/1000, Train Loss: 0.00011346, Validation Loss: 0.00001895, Accuracy: 1.0000\n",
      "Epoch 187/1000, Train Loss: 0.00011213, Validation Loss: 0.00001869, Accuracy: 1.0000\n",
      "Epoch 188/1000, Train Loss: 0.00010987, Validation Loss: 0.00001827, Accuracy: 1.0000\n",
      "Epoch 189/1000, Train Loss: 0.00010855, Validation Loss: 0.00001806, Accuracy: 1.0000\n",
      "Epoch 190/1000, Train Loss: 0.00010646, Validation Loss: 0.00001776, Accuracy: 1.0000\n",
      "Epoch 191/1000, Train Loss: 0.00010498, Validation Loss: 0.00001737, Accuracy: 1.0000\n",
      "Epoch 192/1000, Train Loss: 0.00010328, Validation Loss: 0.00001720, Accuracy: 1.0000\n",
      "Epoch 193/1000, Train Loss: 0.00010185, Validation Loss: 0.00001684, Accuracy: 1.0000\n",
      "Epoch 194/1000, Train Loss: 0.00010010, Validation Loss: 0.00001663, Accuracy: 1.0000\n",
      "Epoch 195/1000, Train Loss: 0.00009877, Validation Loss: 0.00001633, Accuracy: 1.0000\n",
      "Epoch 196/1000, Train Loss: 0.00009714, Validation Loss: 0.00001609, Accuracy: 1.0000\n",
      "Epoch 197/1000, Train Loss: 0.00009569, Validation Loss: 0.00001579, Accuracy: 1.0000\n",
      "Epoch 198/1000, Train Loss: 0.00009441, Validation Loss: 0.00001550, Accuracy: 1.0000\n",
      "Epoch 199/1000, Train Loss: 0.00009292, Validation Loss: 0.00001535, Accuracy: 1.0000\n",
      "Epoch 200/1000, Train Loss: 0.00009152, Validation Loss: 0.00001508, Accuracy: 1.0000\n",
      "Epoch 201/1000, Train Loss: 0.00009014, Validation Loss: 0.00001478, Accuracy: 1.0000\n",
      "Epoch 202/1000, Train Loss: 0.00008861, Validation Loss: 0.00001457, Accuracy: 1.0000\n",
      "Epoch 203/1000, Train Loss: 0.00008737, Validation Loss: 0.00001433, Accuracy: 1.0000\n",
      "Epoch 204/1000, Train Loss: 0.00008600, Validation Loss: 0.00001410, Accuracy: 1.0000\n",
      "Epoch 205/1000, Train Loss: 0.00008503, Validation Loss: 0.00001386, Accuracy: 1.0000\n",
      "Epoch 206/1000, Train Loss: 0.00008371, Validation Loss: 0.00001368, Accuracy: 1.0000\n",
      "Epoch 207/1000, Train Loss: 0.00008236, Validation Loss: 0.00001344, Accuracy: 1.0000\n",
      "Epoch 208/1000, Train Loss: 0.00008125, Validation Loss: 0.00001332, Accuracy: 1.0000\n",
      "Epoch 209/1000, Train Loss: 0.00007990, Validation Loss: 0.00001302, Accuracy: 1.0000\n",
      "Epoch 210/1000, Train Loss: 0.00007900, Validation Loss: 0.00001287, Accuracy: 1.0000\n",
      "Epoch 211/1000, Train Loss: 0.00007756, Validation Loss: 0.00001264, Accuracy: 1.0000\n",
      "Epoch 212/1000, Train Loss: 0.00007659, Validation Loss: 0.00001249, Accuracy: 1.0000\n",
      "Epoch 213/1000, Train Loss: 0.00007537, Validation Loss: 0.00001228, Accuracy: 1.0000\n",
      "Epoch 214/1000, Train Loss: 0.00007441, Validation Loss: 0.00001207, Accuracy: 1.0000\n",
      "Epoch 215/1000, Train Loss: 0.00007327, Validation Loss: 0.00001189, Accuracy: 1.0000\n",
      "Epoch 216/1000, Train Loss: 0.00007231, Validation Loss: 0.00001177, Accuracy: 1.0000\n",
      "Epoch 217/1000, Train Loss: 0.00007124, Validation Loss: 0.00001153, Accuracy: 1.0000\n",
      "Epoch 218/1000, Train Loss: 0.00007020, Validation Loss: 0.00001141, Accuracy: 1.0000\n",
      "Epoch 219/1000, Train Loss: 0.00006924, Validation Loss: 0.00001121, Accuracy: 1.0000\n",
      "Epoch 220/1000, Train Loss: 0.00006825, Validation Loss: 0.00001103, Accuracy: 1.0000\n",
      "Epoch 221/1000, Train Loss: 0.00006746, Validation Loss: 0.00001091, Accuracy: 1.0000\n",
      "Epoch 222/1000, Train Loss: 0.00006633, Validation Loss: 0.00001067, Accuracy: 1.0000\n",
      "Epoch 223/1000, Train Loss: 0.00006543, Validation Loss: 0.00001055, Accuracy: 1.0000\n",
      "Epoch 224/1000, Train Loss: 0.00006451, Validation Loss: 0.00001037, Accuracy: 1.0000\n",
      "Epoch 225/1000, Train Loss: 0.00006359, Validation Loss: 0.00001025, Accuracy: 1.0000\n",
      "Epoch 226/1000, Train Loss: 0.00006284, Validation Loss: 0.00001010, Accuracy: 1.0000\n",
      "Epoch 227/1000, Train Loss: 0.00006190, Validation Loss: 0.00000992, Accuracy: 1.0000\n",
      "Epoch 228/1000, Train Loss: 0.00006102, Validation Loss: 0.00000978, Accuracy: 1.0000\n",
      "Epoch 229/1000, Train Loss: 0.00006020, Validation Loss: 0.00000963, Accuracy: 1.0000\n",
      "Epoch 230/1000, Train Loss: 0.00005933, Validation Loss: 0.00000951, Accuracy: 1.0000\n",
      "Epoch 231/1000, Train Loss: 0.00005867, Validation Loss: 0.00000942, Accuracy: 1.0000\n",
      "Epoch 232/1000, Train Loss: 0.00005781, Validation Loss: 0.00000921, Accuracy: 1.0000\n",
      "Epoch 233/1000, Train Loss: 0.00005694, Validation Loss: 0.00000909, Accuracy: 1.0000\n",
      "Epoch 234/1000, Train Loss: 0.00005640, Validation Loss: 0.00000903, Accuracy: 1.0000\n",
      "Epoch 235/1000, Train Loss: 0.00005549, Validation Loss: 0.00000885, Accuracy: 1.0000\n",
      "Epoch 236/1000, Train Loss: 0.00005467, Validation Loss: 0.00000873, Accuracy: 1.0000\n",
      "Epoch 237/1000, Train Loss: 0.00005400, Validation Loss: 0.00000861, Accuracy: 1.0000\n",
      "Epoch 238/1000, Train Loss: 0.00005318, Validation Loss: 0.00000846, Accuracy: 1.0000\n",
      "Epoch 239/1000, Train Loss: 0.00005254, Validation Loss: 0.00000831, Accuracy: 1.0000\n",
      "Epoch 240/1000, Train Loss: 0.00005195, Validation Loss: 0.00000820, Accuracy: 1.0000\n",
      "Epoch 241/1000, Train Loss: 0.00005115, Validation Loss: 0.00000811, Accuracy: 1.0000\n",
      "Epoch 242/1000, Train Loss: 0.00005042, Validation Loss: 0.00000799, Accuracy: 1.0000\n",
      "Epoch 243/1000, Train Loss: 0.00004983, Validation Loss: 0.00000784, Accuracy: 1.0000\n",
      "Epoch 244/1000, Train Loss: 0.00004911, Validation Loss: 0.00000778, Accuracy: 1.0000\n",
      "Epoch 245/1000, Train Loss: 0.00004849, Validation Loss: 0.00000766, Accuracy: 1.0000\n",
      "Epoch 246/1000, Train Loss: 0.00004778, Validation Loss: 0.00000760, Accuracy: 1.0000\n",
      "Epoch 247/1000, Train Loss: 0.00004732, Validation Loss: 0.00000748, Accuracy: 1.0000\n",
      "Epoch 248/1000, Train Loss: 0.00004665, Validation Loss: 0.00000736, Accuracy: 1.0000\n",
      "Epoch 249/1000, Train Loss: 0.00004596, Validation Loss: 0.00000721, Accuracy: 1.0000\n",
      "Epoch 250/1000, Train Loss: 0.00004540, Validation Loss: 0.00000709, Accuracy: 1.0000\n",
      "Epoch 251/1000, Train Loss: 0.00004477, Validation Loss: 0.00000703, Accuracy: 1.0000\n",
      "Epoch 252/1000, Train Loss: 0.00004420, Validation Loss: 0.00000691, Accuracy: 1.0000\n",
      "Epoch 253/1000, Train Loss: 0.00004369, Validation Loss: 0.00000682, Accuracy: 1.0000\n",
      "Epoch 254/1000, Train Loss: 0.00004313, Validation Loss: 0.00000671, Accuracy: 1.0000\n",
      "Epoch 255/1000, Train Loss: 0.00004254, Validation Loss: 0.00000662, Accuracy: 1.0000\n",
      "Epoch 256/1000, Train Loss: 0.00004201, Validation Loss: 0.00000656, Accuracy: 1.0000\n",
      "Epoch 257/1000, Train Loss: 0.00004144, Validation Loss: 0.00000644, Accuracy: 1.0000\n",
      "Epoch 258/1000, Train Loss: 0.00004093, Validation Loss: 0.00000638, Accuracy: 1.0000\n",
      "Epoch 259/1000, Train Loss: 0.00004040, Validation Loss: 0.00000626, Accuracy: 1.0000\n",
      "Epoch 260/1000, Train Loss: 0.00003989, Validation Loss: 0.00000620, Accuracy: 1.0000\n",
      "Epoch 261/1000, Train Loss: 0.00003950, Validation Loss: 0.00000611, Accuracy: 1.0000\n",
      "Epoch 262/1000, Train Loss: 0.00003888, Validation Loss: 0.00000602, Accuracy: 1.0000\n",
      "Epoch 263/1000, Train Loss: 0.00003839, Validation Loss: 0.00000596, Accuracy: 1.0000\n",
      "Epoch 264/1000, Train Loss: 0.00003794, Validation Loss: 0.00000587, Accuracy: 1.0000\n",
      "Epoch 265/1000, Train Loss: 0.00003751, Validation Loss: 0.00000581, Accuracy: 1.0000\n",
      "Epoch 266/1000, Train Loss: 0.00003697, Validation Loss: 0.00000572, Accuracy: 1.0000\n",
      "Epoch 267/1000, Train Loss: 0.00003650, Validation Loss: 0.00000563, Accuracy: 1.0000\n",
      "Epoch 268/1000, Train Loss: 0.00003609, Validation Loss: 0.00000557, Accuracy: 1.0000\n",
      "Epoch 269/1000, Train Loss: 0.00003558, Validation Loss: 0.00000551, Accuracy: 1.0000\n",
      "Epoch 270/1000, Train Loss: 0.00003515, Validation Loss: 0.00000542, Accuracy: 1.0000\n",
      "Epoch 271/1000, Train Loss: 0.00003472, Validation Loss: 0.00000539, Accuracy: 1.0000\n",
      "Epoch 272/1000, Train Loss: 0.00003425, Validation Loss: 0.00000527, Accuracy: 1.0000\n",
      "Epoch 273/1000, Train Loss: 0.00003387, Validation Loss: 0.00000522, Accuracy: 1.0000\n",
      "Epoch 274/1000, Train Loss: 0.00003342, Validation Loss: 0.00000516, Accuracy: 1.0000\n",
      "Epoch 275/1000, Train Loss: 0.00003305, Validation Loss: 0.00000510, Accuracy: 1.0000\n",
      "Epoch 276/1000, Train Loss: 0.00003263, Validation Loss: 0.00000504, Accuracy: 1.0000\n",
      "Epoch 277/1000, Train Loss: 0.00003215, Validation Loss: 0.00000492, Accuracy: 1.0000\n",
      "Epoch 278/1000, Train Loss: 0.00003186, Validation Loss: 0.00000486, Accuracy: 1.0000\n",
      "Epoch 279/1000, Train Loss: 0.00003139, Validation Loss: 0.00000480, Accuracy: 1.0000\n",
      "Epoch 280/1000, Train Loss: 0.00003110, Validation Loss: 0.00000474, Accuracy: 1.0000\n",
      "Epoch 281/1000, Train Loss: 0.00003072, Validation Loss: 0.00000468, Accuracy: 1.0000\n",
      "Epoch 282/1000, Train Loss: 0.00003024, Validation Loss: 0.00000462, Accuracy: 1.0000\n",
      "Epoch 283/1000, Train Loss: 0.00002996, Validation Loss: 0.00000453, Accuracy: 1.0000\n",
      "Epoch 284/1000, Train Loss: 0.00002954, Validation Loss: 0.00000447, Accuracy: 1.0000\n",
      "Epoch 285/1000, Train Loss: 0.00002918, Validation Loss: 0.00000441, Accuracy: 1.0000\n",
      "Epoch 286/1000, Train Loss: 0.00002886, Validation Loss: 0.00000435, Accuracy: 1.0000\n",
      "Epoch 287/1000, Train Loss: 0.00002846, Validation Loss: 0.00000429, Accuracy: 1.0000\n",
      "Epoch 288/1000, Train Loss: 0.00002819, Validation Loss: 0.00000423, Accuracy: 1.0000\n",
      "Epoch 289/1000, Train Loss: 0.00002777, Validation Loss: 0.00000417, Accuracy: 1.0000\n",
      "Epoch 290/1000, Train Loss: 0.00002744, Validation Loss: 0.00000414, Accuracy: 1.0000\n",
      "Epoch 291/1000, Train Loss: 0.00002715, Validation Loss: 0.00000408, Accuracy: 1.0000\n",
      "Epoch 292/1000, Train Loss: 0.00002683, Validation Loss: 0.00000402, Accuracy: 1.0000\n",
      "Epoch 293/1000, Train Loss: 0.00002649, Validation Loss: 0.00000396, Accuracy: 1.0000\n",
      "Epoch 294/1000, Train Loss: 0.00002616, Validation Loss: 0.00000390, Accuracy: 1.0000\n",
      "Epoch 295/1000, Train Loss: 0.00002587, Validation Loss: 0.00000390, Accuracy: 1.0000\n",
      "Epoch 296/1000, Train Loss: 0.00002554, Validation Loss: 0.00000384, Accuracy: 1.0000\n",
      "Epoch 297/1000, Train Loss: 0.00002534, Validation Loss: 0.00000378, Accuracy: 1.0000\n",
      "Epoch 298/1000, Train Loss: 0.00002492, Validation Loss: 0.00000373, Accuracy: 1.0000\n",
      "Epoch 299/1000, Train Loss: 0.00002470, Validation Loss: 0.00000367, Accuracy: 1.0000\n",
      "Epoch 300/1000, Train Loss: 0.00002438, Validation Loss: 0.00000367, Accuracy: 1.0000\n",
      "Epoch 301/1000, Train Loss: 0.00002414, Validation Loss: 0.00000361, Accuracy: 1.0000\n",
      "Epoch 302/1000, Train Loss: 0.00002378, Validation Loss: 0.00000355, Accuracy: 1.0000\n",
      "Epoch 303/1000, Train Loss: 0.00002351, Validation Loss: 0.00000352, Accuracy: 1.0000\n",
      "Epoch 304/1000, Train Loss: 0.00002325, Validation Loss: 0.00000346, Accuracy: 1.0000\n",
      "Epoch 305/1000, Train Loss: 0.00002297, Validation Loss: 0.00000343, Accuracy: 1.0000\n",
      "Epoch 306/1000, Train Loss: 0.00002269, Validation Loss: 0.00000340, Accuracy: 1.0000\n",
      "Epoch 307/1000, Train Loss: 0.00002249, Validation Loss: 0.00000334, Accuracy: 1.0000\n",
      "Epoch 308/1000, Train Loss: 0.00002218, Validation Loss: 0.00000334, Accuracy: 1.0000\n",
      "Epoch 309/1000, Train Loss: 0.00002192, Validation Loss: 0.00000328, Accuracy: 1.0000\n",
      "Epoch 310/1000, Train Loss: 0.00002168, Validation Loss: 0.00000322, Accuracy: 1.0000\n",
      "Epoch 311/1000, Train Loss: 0.00002144, Validation Loss: 0.00000316, Accuracy: 1.0000\n",
      "Epoch 312/1000, Train Loss: 0.00002116, Validation Loss: 0.00000316, Accuracy: 1.0000\n",
      "Epoch 313/1000, Train Loss: 0.00002092, Validation Loss: 0.00000310, Accuracy: 1.0000\n",
      "Epoch 314/1000, Train Loss: 0.00002066, Validation Loss: 0.00000307, Accuracy: 1.0000\n",
      "Epoch 315/1000, Train Loss: 0.00002049, Validation Loss: 0.00000301, Accuracy: 1.0000\n",
      "Epoch 316/1000, Train Loss: 0.00002019, Validation Loss: 0.00000301, Accuracy: 1.0000\n",
      "Epoch 317/1000, Train Loss: 0.00001998, Validation Loss: 0.00000295, Accuracy: 1.0000\n",
      "Epoch 318/1000, Train Loss: 0.00001974, Validation Loss: 0.00000292, Accuracy: 1.0000\n",
      "Epoch 319/1000, Train Loss: 0.00001953, Validation Loss: 0.00000289, Accuracy: 1.0000\n",
      "Epoch 320/1000, Train Loss: 0.00001929, Validation Loss: 0.00000283, Accuracy: 1.0000\n",
      "Epoch 321/1000, Train Loss: 0.00001906, Validation Loss: 0.00000283, Accuracy: 1.0000\n",
      "Epoch 322/1000, Train Loss: 0.00001884, Validation Loss: 0.00000277, Accuracy: 1.0000\n",
      "Epoch 323/1000, Train Loss: 0.00001862, Validation Loss: 0.00000277, Accuracy: 1.0000\n",
      "Epoch 324/1000, Train Loss: 0.00001844, Validation Loss: 0.00000271, Accuracy: 1.0000\n",
      "Epoch 325/1000, Train Loss: 0.00001822, Validation Loss: 0.00000271, Accuracy: 1.0000\n",
      "Epoch 326/1000, Train Loss: 0.00001799, Validation Loss: 0.00000265, Accuracy: 1.0000\n",
      "Epoch 327/1000, Train Loss: 0.00001781, Validation Loss: 0.00000265, Accuracy: 1.0000\n",
      "Epoch 328/1000, Train Loss: 0.00001759, Validation Loss: 0.00000259, Accuracy: 1.0000\n",
      "Epoch 329/1000, Train Loss: 0.00001743, Validation Loss: 0.00000259, Accuracy: 1.0000\n",
      "Epoch 330/1000, Train Loss: 0.00001723, Validation Loss: 0.00000253, Accuracy: 1.0000\n",
      "Epoch 331/1000, Train Loss: 0.00001703, Validation Loss: 0.00000250, Accuracy: 1.0000\n",
      "Epoch 332/1000, Train Loss: 0.00001681, Validation Loss: 0.00000247, Accuracy: 1.0000\n",
      "Epoch 333/1000, Train Loss: 0.00001661, Validation Loss: 0.00000244, Accuracy: 1.0000\n",
      "Epoch 334/1000, Train Loss: 0.00001652, Validation Loss: 0.00000244, Accuracy: 1.0000\n",
      "Epoch 335/1000, Train Loss: 0.00001625, Validation Loss: 0.00000238, Accuracy: 1.0000\n",
      "Epoch 336/1000, Train Loss: 0.00001606, Validation Loss: 0.00000235, Accuracy: 1.0000\n",
      "Epoch 337/1000, Train Loss: 0.00001589, Validation Loss: 0.00000232, Accuracy: 1.0000\n",
      "Epoch 338/1000, Train Loss: 0.00001574, Validation Loss: 0.00000232, Accuracy: 1.0000\n",
      "Epoch 339/1000, Train Loss: 0.00001553, Validation Loss: 0.00000226, Accuracy: 1.0000\n",
      "Epoch 340/1000, Train Loss: 0.00001535, Validation Loss: 0.00000226, Accuracy: 1.0000\n",
      "Epoch 341/1000, Train Loss: 0.00001517, Validation Loss: 0.00000221, Accuracy: 1.0000\n",
      "Epoch 342/1000, Train Loss: 0.00001504, Validation Loss: 0.00000221, Accuracy: 1.0000\n",
      "Epoch 343/1000, Train Loss: 0.00001484, Validation Loss: 0.00000212, Accuracy: 1.0000\n",
      "Epoch 344/1000, Train Loss: 0.00001467, Validation Loss: 0.00000212, Accuracy: 1.0000\n",
      "Epoch 345/1000, Train Loss: 0.00001455, Validation Loss: 0.00000209, Accuracy: 1.0000\n",
      "Epoch 346/1000, Train Loss: 0.00001435, Validation Loss: 0.00000203, Accuracy: 1.0000\n",
      "Epoch 347/1000, Train Loss: 0.00001421, Validation Loss: 0.00000203, Accuracy: 1.0000\n",
      "Epoch 348/1000, Train Loss: 0.00001407, Validation Loss: 0.00000200, Accuracy: 1.0000\n",
      "Epoch 349/1000, Train Loss: 0.00001388, Validation Loss: 0.00000197, Accuracy: 1.0000\n",
      "Epoch 350/1000, Train Loss: 0.00001376, Validation Loss: 0.00000194, Accuracy: 1.0000\n",
      "Epoch 351/1000, Train Loss: 0.00001362, Validation Loss: 0.00000194, Accuracy: 1.0000\n",
      "Epoch 352/1000, Train Loss: 0.00001343, Validation Loss: 0.00000191, Accuracy: 1.0000\n",
      "Epoch 353/1000, Train Loss: 0.00001328, Validation Loss: 0.00000188, Accuracy: 1.0000\n",
      "Epoch 354/1000, Train Loss: 0.00001313, Validation Loss: 0.00000185, Accuracy: 1.0000\n",
      "Epoch 355/1000, Train Loss: 0.00001297, Validation Loss: 0.00000182, Accuracy: 1.0000\n",
      "Epoch 356/1000, Train Loss: 0.00001285, Validation Loss: 0.00000182, Accuracy: 1.0000\n",
      "Epoch 357/1000, Train Loss: 0.00001269, Validation Loss: 0.00000179, Accuracy: 1.0000\n",
      "Epoch 358/1000, Train Loss: 0.00001255, Validation Loss: 0.00000176, Accuracy: 1.0000\n",
      "Epoch 359/1000, Train Loss: 0.00001248, Validation Loss: 0.00000176, Accuracy: 1.0000\n",
      "Epoch 360/1000, Train Loss: 0.00001230, Validation Loss: 0.00000170, Accuracy: 1.0000\n",
      "Epoch 361/1000, Train Loss: 0.00001219, Validation Loss: 0.00000170, Accuracy: 1.0000\n",
      "Epoch 362/1000, Train Loss: 0.00001203, Validation Loss: 0.00000170, Accuracy: 1.0000\n",
      "Epoch 363/1000, Train Loss: 0.00001191, Validation Loss: 0.00000164, Accuracy: 1.0000\n",
      "Epoch 364/1000, Train Loss: 0.00001176, Validation Loss: 0.00000164, Accuracy: 1.0000\n",
      "Epoch 365/1000, Train Loss: 0.00001163, Validation Loss: 0.00000164, Accuracy: 1.0000\n",
      "Epoch 366/1000, Train Loss: 0.00001153, Validation Loss: 0.00000161, Accuracy: 1.0000\n",
      "Epoch 367/1000, Train Loss: 0.00001137, Validation Loss: 0.00000158, Accuracy: 1.0000\n",
      "Epoch 368/1000, Train Loss: 0.00001126, Validation Loss: 0.00000158, Accuracy: 1.0000\n",
      "Epoch 369/1000, Train Loss: 0.00001116, Validation Loss: 0.00000155, Accuracy: 1.0000\n",
      "Epoch 370/1000, Train Loss: 0.00001102, Validation Loss: 0.00000152, Accuracy: 1.0000\n",
      "Epoch 371/1000, Train Loss: 0.00001091, Validation Loss: 0.00000152, Accuracy: 1.0000\n",
      "Epoch 372/1000, Train Loss: 0.00001080, Validation Loss: 0.00000149, Accuracy: 1.0000\n",
      "Epoch 373/1000, Train Loss: 0.00001066, Validation Loss: 0.00000149, Accuracy: 1.0000\n",
      "Epoch 374/1000, Train Loss: 0.00001055, Validation Loss: 0.00000146, Accuracy: 1.0000\n",
      "Epoch 375/1000, Train Loss: 0.00001043, Validation Loss: 0.00000146, Accuracy: 1.0000\n",
      "Epoch 376/1000, Train Loss: 0.00001032, Validation Loss: 0.00000143, Accuracy: 1.0000\n",
      "Epoch 377/1000, Train Loss: 0.00001023, Validation Loss: 0.00000140, Accuracy: 1.0000\n",
      "Epoch 378/1000, Train Loss: 0.00001013, Validation Loss: 0.00000140, Accuracy: 1.0000\n",
      "Epoch 379/1000, Train Loss: 0.00000998, Validation Loss: 0.00000137, Accuracy: 1.0000\n",
      "Epoch 380/1000, Train Loss: 0.00000991, Validation Loss: 0.00000137, Accuracy: 1.0000\n",
      "Epoch 381/1000, Train Loss: 0.00000978, Validation Loss: 0.00000137, Accuracy: 1.0000\n",
      "Epoch 382/1000, Train Loss: 0.00000971, Validation Loss: 0.00000134, Accuracy: 1.0000\n",
      "Epoch 383/1000, Train Loss: 0.00000958, Validation Loss: 0.00000131, Accuracy: 1.0000\n",
      "Epoch 384/1000, Train Loss: 0.00000947, Validation Loss: 0.00000131, Accuracy: 1.0000\n",
      "Epoch 385/1000, Train Loss: 0.00000937, Validation Loss: 0.00000131, Accuracy: 1.0000\n",
      "Epoch 386/1000, Train Loss: 0.00000931, Validation Loss: 0.00000125, Accuracy: 1.0000\n",
      "Epoch 387/1000, Train Loss: 0.00000918, Validation Loss: 0.00000125, Accuracy: 1.0000\n",
      "Epoch 388/1000, Train Loss: 0.00000908, Validation Loss: 0.00000125, Accuracy: 1.0000\n",
      "Epoch 389/1000, Train Loss: 0.00000899, Validation Loss: 0.00000125, Accuracy: 1.0000\n",
      "Epoch 390/1000, Train Loss: 0.00000890, Validation Loss: 0.00000119, Accuracy: 1.0000\n",
      "Epoch 391/1000, Train Loss: 0.00000879, Validation Loss: 0.00000119, Accuracy: 1.0000\n",
      "Epoch 392/1000, Train Loss: 0.00000871, Validation Loss: 0.00000119, Accuracy: 1.0000\n",
      "Epoch 393/1000, Train Loss: 0.00000861, Validation Loss: 0.00000119, Accuracy: 1.0000\n",
      "Epoch 394/1000, Train Loss: 0.00000852, Validation Loss: 0.00000116, Accuracy: 1.0000\n",
      "Epoch 395/1000, Train Loss: 0.00000842, Validation Loss: 0.00000113, Accuracy: 1.0000\n",
      "Epoch 396/1000, Train Loss: 0.00000834, Validation Loss: 0.00000113, Accuracy: 1.0000\n",
      "Epoch 397/1000, Train Loss: 0.00000824, Validation Loss: 0.00000113, Accuracy: 1.0000\n",
      "Epoch 398/1000, Train Loss: 0.00000816, Validation Loss: 0.00000110, Accuracy: 1.0000\n",
      "Epoch 399/1000, Train Loss: 0.00000808, Validation Loss: 0.00000110, Accuracy: 1.0000\n",
      "Epoch 400/1000, Train Loss: 0.00000799, Validation Loss: 0.00000107, Accuracy: 1.0000\n",
      "Epoch 401/1000, Train Loss: 0.00000793, Validation Loss: 0.00000107, Accuracy: 1.0000\n",
      "Epoch 402/1000, Train Loss: 0.00000783, Validation Loss: 0.00000107, Accuracy: 1.0000\n",
      "Epoch 403/1000, Train Loss: 0.00000774, Validation Loss: 0.00000104, Accuracy: 1.0000\n",
      "Epoch 404/1000, Train Loss: 0.00000765, Validation Loss: 0.00000104, Accuracy: 1.0000\n",
      "Epoch 405/1000, Train Loss: 0.00000758, Validation Loss: 0.00000104, Accuracy: 1.0000\n",
      "Epoch 406/1000, Train Loss: 0.00000750, Validation Loss: 0.00000101, Accuracy: 1.0000\n",
      "Epoch 407/1000, Train Loss: 0.00000742, Validation Loss: 0.00000101, Accuracy: 1.0000\n",
      "Epoch 408/1000, Train Loss: 0.00000734, Validation Loss: 0.00000098, Accuracy: 1.0000\n",
      "Epoch 409/1000, Train Loss: 0.00000729, Validation Loss: 0.00000098, Accuracy: 1.0000\n",
      "Epoch 410/1000, Train Loss: 0.00000720, Validation Loss: 0.00000098, Accuracy: 1.0000\n",
      "Epoch 411/1000, Train Loss: 0.00000711, Validation Loss: 0.00000098, Accuracy: 1.0000\n",
      "Epoch 412/1000, Train Loss: 0.00000704, Validation Loss: 0.00000092, Accuracy: 1.0000\n",
      "Epoch 413/1000, Train Loss: 0.00000699, Validation Loss: 0.00000092, Accuracy: 1.0000\n",
      "Epoch 414/1000, Train Loss: 0.00000691, Validation Loss: 0.00000092, Accuracy: 1.0000\n",
      "Epoch 415/1000, Train Loss: 0.00000684, Validation Loss: 0.00000092, Accuracy: 1.0000\n",
      "Epoch 416/1000, Train Loss: 0.00000676, Validation Loss: 0.00000092, Accuracy: 1.0000\n",
      "Epoch 417/1000, Train Loss: 0.00000669, Validation Loss: 0.00000092, Accuracy: 1.0000\n",
      "Epoch 418/1000, Train Loss: 0.00000662, Validation Loss: 0.00000086, Accuracy: 1.0000\n",
      "Epoch 419/1000, Train Loss: 0.00000655, Validation Loss: 0.00000086, Accuracy: 1.0000\n",
      "Epoch 420/1000, Train Loss: 0.00000649, Validation Loss: 0.00000086, Accuracy: 1.0000\n",
      "Epoch 421/1000, Train Loss: 0.00000641, Validation Loss: 0.00000086, Accuracy: 1.0000\n",
      "Epoch 422/1000, Train Loss: 0.00000635, Validation Loss: 0.00000086, Accuracy: 1.0000\n",
      "Epoch 423/1000, Train Loss: 0.00000628, Validation Loss: 0.00000083, Accuracy: 1.0000\n",
      "Epoch 424/1000, Train Loss: 0.00000623, Validation Loss: 0.00000080, Accuracy: 1.0000\n",
      "Epoch 425/1000, Train Loss: 0.00000614, Validation Loss: 0.00000080, Accuracy: 1.0000\n",
      "Epoch 426/1000, Train Loss: 0.00000609, Validation Loss: 0.00000080, Accuracy: 1.0000\n",
      "Epoch 427/1000, Train Loss: 0.00000603, Validation Loss: 0.00000080, Accuracy: 1.0000\n",
      "Epoch 428/1000, Train Loss: 0.00000595, Validation Loss: 0.00000080, Accuracy: 1.0000\n",
      "Epoch 429/1000, Train Loss: 0.00000590, Validation Loss: 0.00000077, Accuracy: 1.0000\n",
      "Epoch 430/1000, Train Loss: 0.00000584, Validation Loss: 0.00000077, Accuracy: 1.0000\n",
      "Epoch 431/1000, Train Loss: 0.00000577, Validation Loss: 0.00000077, Accuracy: 1.0000\n",
      "Epoch 432/1000, Train Loss: 0.00000572, Validation Loss: 0.00000075, Accuracy: 1.0000\n",
      "Epoch 433/1000, Train Loss: 0.00000568, Validation Loss: 0.00000075, Accuracy: 1.0000\n",
      "Epoch 434/1000, Train Loss: 0.00000560, Validation Loss: 0.00000075, Accuracy: 1.0000\n",
      "Epoch 435/1000, Train Loss: 0.00000554, Validation Loss: 0.00000075, Accuracy: 1.0000\n",
      "Epoch 436/1000, Train Loss: 0.00000549, Validation Loss: 0.00000072, Accuracy: 1.0000\n",
      "Epoch 437/1000, Train Loss: 0.00000542, Validation Loss: 0.00000072, Accuracy: 1.0000\n",
      "Epoch 438/1000, Train Loss: 0.00000537, Validation Loss: 0.00000072, Accuracy: 1.0000\n",
      "Epoch 439/1000, Train Loss: 0.00000533, Validation Loss: 0.00000072, Accuracy: 1.0000\n",
      "Epoch 440/1000, Train Loss: 0.00000527, Validation Loss: 0.00000069, Accuracy: 1.0000\n",
      "Epoch 441/1000, Train Loss: 0.00000523, Validation Loss: 0.00000069, Accuracy: 1.0000\n",
      "Epoch 442/1000, Train Loss: 0.00000517, Validation Loss: 0.00000069, Accuracy: 1.0000\n",
      "Epoch 443/1000, Train Loss: 0.00000510, Validation Loss: 0.00000066, Accuracy: 1.0000\n",
      "Epoch 444/1000, Train Loss: 0.00000506, Validation Loss: 0.00000066, Accuracy: 1.0000\n",
      "Epoch 445/1000, Train Loss: 0.00000501, Validation Loss: 0.00000066, Accuracy: 1.0000\n",
      "Epoch 446/1000, Train Loss: 0.00000497, Validation Loss: 0.00000066, Accuracy: 1.0000\n",
      "Epoch 447/1000, Train Loss: 0.00000490, Validation Loss: 0.00000066, Accuracy: 1.0000\n",
      "Epoch 448/1000, Train Loss: 0.00000486, Validation Loss: 0.00000066, Accuracy: 1.0000\n",
      "Epoch 449/1000, Train Loss: 0.00000481, Validation Loss: 0.00000063, Accuracy: 1.0000\n",
      "Epoch 450/1000, Train Loss: 0.00000475, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 451/1000, Train Loss: 0.00000471, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 452/1000, Train Loss: 0.00000466, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 453/1000, Train Loss: 0.00000461, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 454/1000, Train Loss: 0.00000457, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 455/1000, Train Loss: 0.00000451, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 456/1000, Train Loss: 0.00000447, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 457/1000, Train Loss: 0.00000443, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 458/1000, Train Loss: 0.00000439, Validation Loss: 0.00000060, Accuracy: 1.0000\n",
      "Epoch 459/1000, Train Loss: 0.00000435, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 460/1000, Train Loss: 0.00000430, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 461/1000, Train Loss: 0.00000425, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 462/1000, Train Loss: 0.00000421, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 463/1000, Train Loss: 0.00000417, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 464/1000, Train Loss: 0.00000412, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 465/1000, Train Loss: 0.00000409, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 466/1000, Train Loss: 0.00000405, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 467/1000, Train Loss: 0.00000400, Validation Loss: 0.00000054, Accuracy: 1.0000\n",
      "Epoch 468/1000, Train Loss: 0.00000396, Validation Loss: 0.00000051, Accuracy: 1.0000\n",
      "Epoch 469/1000, Train Loss: 0.00000393, Validation Loss: 0.00000051, Accuracy: 1.0000\n",
      "Epoch 470/1000, Train Loss: 0.00000389, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 471/1000, Train Loss: 0.00000384, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 472/1000, Train Loss: 0.00000381, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 473/1000, Train Loss: 0.00000377, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 474/1000, Train Loss: 0.00000373, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 475/1000, Train Loss: 0.00000370, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 476/1000, Train Loss: 0.00000365, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 477/1000, Train Loss: 0.00000362, Validation Loss: 0.00000048, Accuracy: 1.0000\n",
      "Epoch 478/1000, Train Loss: 0.00000359, Validation Loss: 0.00000045, Accuracy: 1.0000\n",
      "Epoch 479/1000, Train Loss: 0.00000356, Validation Loss: 0.00000045, Accuracy: 1.0000\n",
      "Epoch 480/1000, Train Loss: 0.00000351, Validation Loss: 0.00000045, Accuracy: 1.0000\n",
      "Epoch 481/1000, Train Loss: 0.00000349, Validation Loss: 0.00000045, Accuracy: 1.0000\n",
      "Epoch 482/1000, Train Loss: 0.00000345, Validation Loss: 0.00000045, Accuracy: 1.0000\n",
      "Epoch 483/1000, Train Loss: 0.00000341, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 484/1000, Train Loss: 0.00000337, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 485/1000, Train Loss: 0.00000333, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 486/1000, Train Loss: 0.00000332, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 487/1000, Train Loss: 0.00000327, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 488/1000, Train Loss: 0.00000325, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 489/1000, Train Loss: 0.00000321, Validation Loss: 0.00000042, Accuracy: 1.0000\n",
      "Epoch 490/1000, Train Loss: 0.00000318, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 491/1000, Train Loss: 0.00000314, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 492/1000, Train Loss: 0.00000311, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 493/1000, Train Loss: 0.00000308, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 494/1000, Train Loss: 0.00000305, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 495/1000, Train Loss: 0.00000302, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 496/1000, Train Loss: 0.00000299, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 497/1000, Train Loss: 0.00000296, Validation Loss: 0.00000039, Accuracy: 1.0000\n",
      "Epoch 498/1000, Train Loss: 0.00000294, Validation Loss: 0.00000036, Accuracy: 1.0000\n",
      "Epoch 499/1000, Train Loss: 0.00000290, Validation Loss: 0.00000036, Accuracy: 1.0000\n",
      "Epoch 500/1000, Train Loss: 0.00000288, Validation Loss: 0.00000036, Accuracy: 1.0000\n",
      "Epoch 501/1000, Train Loss: 0.00000285, Validation Loss: 0.00000036, Accuracy: 1.0000\n",
      "Epoch 502/1000, Train Loss: 0.00000282, Validation Loss: 0.00000036, Accuracy: 1.0000\n",
      "Epoch 503/1000, Train Loss: 0.00000280, Validation Loss: 0.00000036, Accuracy: 1.0000\n",
      "Epoch 504/1000, Train Loss: 0.00000276, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 505/1000, Train Loss: 0.00000273, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 506/1000, Train Loss: 0.00000271, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 507/1000, Train Loss: 0.00000269, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 508/1000, Train Loss: 0.00000266, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 509/1000, Train Loss: 0.00000263, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 510/1000, Train Loss: 0.00000260, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 511/1000, Train Loss: 0.00000257, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 512/1000, Train Loss: 0.00000255, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 513/1000, Train Loss: 0.00000253, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 514/1000, Train Loss: 0.00000250, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 515/1000, Train Loss: 0.00000248, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 516/1000, Train Loss: 0.00000245, Validation Loss: 0.00000033, Accuracy: 1.0000\n",
      "Epoch 517/1000, Train Loss: 0.00000243, Validation Loss: 0.00000030, Accuracy: 1.0000\n",
      "Epoch 518/1000, Train Loss: 0.00000240, Validation Loss: 0.00000030, Accuracy: 1.0000\n",
      "Epoch 519/1000, Train Loss: 0.00000238, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 520/1000, Train Loss: 0.00000235, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 521/1000, Train Loss: 0.00000234, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 522/1000, Train Loss: 0.00000231, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 523/1000, Train Loss: 0.00000229, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 524/1000, Train Loss: 0.00000227, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 525/1000, Train Loss: 0.00000225, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 526/1000, Train Loss: 0.00000222, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 527/1000, Train Loss: 0.00000219, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 528/1000, Train Loss: 0.00000218, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 529/1000, Train Loss: 0.00000215, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 530/1000, Train Loss: 0.00000214, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 531/1000, Train Loss: 0.00000212, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 532/1000, Train Loss: 0.00000209, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 533/1000, Train Loss: 0.00000207, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 534/1000, Train Loss: 0.00000205, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 535/1000, Train Loss: 0.00000203, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 536/1000, Train Loss: 0.00000201, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 537/1000, Train Loss: 0.00000199, Validation Loss: 0.00000027, Accuracy: 1.0000\n",
      "Epoch 538/1000, Train Loss: 0.00000197, Validation Loss: 0.00000024, Accuracy: 1.0000\n",
      "Epoch 539/1000, Train Loss: 0.00000196, Validation Loss: 0.00000024, Accuracy: 1.0000\n",
      "Epoch 540/1000, Train Loss: 0.00000194, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 541/1000, Train Loss: 0.00000192, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 542/1000, Train Loss: 0.00000190, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 543/1000, Train Loss: 0.00000189, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 544/1000, Train Loss: 0.00000186, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 545/1000, Train Loss: 0.00000184, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 546/1000, Train Loss: 0.00000183, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 547/1000, Train Loss: 0.00000181, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 548/1000, Train Loss: 0.00000179, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 549/1000, Train Loss: 0.00000177, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 550/1000, Train Loss: 0.00000175, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 551/1000, Train Loss: 0.00000174, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 552/1000, Train Loss: 0.00000172, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 553/1000, Train Loss: 0.00000171, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 554/1000, Train Loss: 0.00000169, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 555/1000, Train Loss: 0.00000168, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 556/1000, Train Loss: 0.00000166, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 557/1000, Train Loss: 0.00000164, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 558/1000, Train Loss: 0.00000163, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 559/1000, Train Loss: 0.00000161, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 560/1000, Train Loss: 0.00000159, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 561/1000, Train Loss: 0.00000159, Validation Loss: 0.00000021, Accuracy: 1.0000\n",
      "Epoch 562/1000, Train Loss: 0.00000157, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 563/1000, Train Loss: 0.00000155, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 564/1000, Train Loss: 0.00000154, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 565/1000, Train Loss: 0.00000152, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 566/1000, Train Loss: 0.00000150, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 567/1000, Train Loss: 0.00000149, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 568/1000, Train Loss: 0.00000148, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 569/1000, Train Loss: 0.00000146, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 570/1000, Train Loss: 0.00000145, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 571/1000, Train Loss: 0.00000143, Validation Loss: 0.00000018, Accuracy: 1.0000\n",
      "Epoch 572/1000, Train Loss: 0.00000142, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 573/1000, Train Loss: 0.00000141, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 574/1000, Train Loss: 0.00000139, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 575/1000, Train Loss: 0.00000138, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 576/1000, Train Loss: 0.00000136, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 577/1000, Train Loss: 0.00000136, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 578/1000, Train Loss: 0.00000134, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 579/1000, Train Loss: 0.00000133, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 580/1000, Train Loss: 0.00000132, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 581/1000, Train Loss: 0.00000130, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 582/1000, Train Loss: 0.00000129, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 583/1000, Train Loss: 0.00000128, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 584/1000, Train Loss: 0.00000127, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 585/1000, Train Loss: 0.00000125, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 586/1000, Train Loss: 0.00000124, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 587/1000, Train Loss: 0.00000123, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 588/1000, Train Loss: 0.00000122, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 589/1000, Train Loss: 0.00000120, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 590/1000, Train Loss: 0.00000120, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 591/1000, Train Loss: 0.00000118, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 592/1000, Train Loss: 0.00000117, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 593/1000, Train Loss: 0.00000117, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 594/1000, Train Loss: 0.00000116, Validation Loss: 0.00000015, Accuracy: 1.0000\n",
      "Epoch 595/1000, Train Loss: 0.00000114, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 596/1000, Train Loss: 0.00000113, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 597/1000, Train Loss: 0.00000112, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 598/1000, Train Loss: 0.00000111, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 599/1000, Train Loss: 0.00000109, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 600/1000, Train Loss: 0.00000108, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 601/1000, Train Loss: 0.00000107, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 602/1000, Train Loss: 0.00000107, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 603/1000, Train Loss: 0.00000105, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 604/1000, Train Loss: 0.00000104, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 605/1000, Train Loss: 0.00000103, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 606/1000, Train Loss: 0.00000102, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 607/1000, Train Loss: 0.00000101, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 608/1000, Train Loss: 0.00000101, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 609/1000, Train Loss: 0.00000099, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 610/1000, Train Loss: 0.00000098, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 611/1000, Train Loss: 0.00000096, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 612/1000, Train Loss: 0.00000096, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 613/1000, Train Loss: 0.00000096, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 614/1000, Train Loss: 0.00000095, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 615/1000, Train Loss: 0.00000094, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 616/1000, Train Loss: 0.00000093, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 617/1000, Train Loss: 0.00000092, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 618/1000, Train Loss: 0.00000091, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 619/1000, Train Loss: 0.00000091, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 620/1000, Train Loss: 0.00000089, Validation Loss: 0.00000012, Accuracy: 1.0000\n",
      "Epoch 621/1000, Train Loss: 0.00000088, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 622/1000, Train Loss: 0.00000088, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 623/1000, Train Loss: 0.00000087, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 624/1000, Train Loss: 0.00000086, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 625/1000, Train Loss: 0.00000085, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 626/1000, Train Loss: 0.00000084, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 627/1000, Train Loss: 0.00000084, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 628/1000, Train Loss: 0.00000083, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 629/1000, Train Loss: 0.00000082, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 630/1000, Train Loss: 0.00000082, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 631/1000, Train Loss: 0.00000080, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 632/1000, Train Loss: 0.00000080, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 633/1000, Train Loss: 0.00000078, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 634/1000, Train Loss: 0.00000077, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 635/1000, Train Loss: 0.00000077, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 636/1000, Train Loss: 0.00000076, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 637/1000, Train Loss: 0.00000076, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 638/1000, Train Loss: 0.00000075, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 639/1000, Train Loss: 0.00000074, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 640/1000, Train Loss: 0.00000074, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 641/1000, Train Loss: 0.00000073, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 642/1000, Train Loss: 0.00000073, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 643/1000, Train Loss: 0.00000072, Validation Loss: 0.00000009, Accuracy: 1.0000\n",
      "Epoch 644/1000, Train Loss: 0.00000071, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 645/1000, Train Loss: 0.00000071, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 646/1000, Train Loss: 0.00000069, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 647/1000, Train Loss: 0.00000069, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 648/1000, Train Loss: 0.00000069, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 649/1000, Train Loss: 0.00000068, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 650/1000, Train Loss: 0.00000067, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 651/1000, Train Loss: 0.00000066, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 652/1000, Train Loss: 0.00000065, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 653/1000, Train Loss: 0.00000065, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 654/1000, Train Loss: 0.00000064, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 655/1000, Train Loss: 0.00000064, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 656/1000, Train Loss: 0.00000063, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 657/1000, Train Loss: 0.00000062, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 658/1000, Train Loss: 0.00000062, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 659/1000, Train Loss: 0.00000061, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 660/1000, Train Loss: 0.00000060, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 661/1000, Train Loss: 0.00000060, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 662/1000, Train Loss: 0.00000060, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 663/1000, Train Loss: 0.00000058, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 664/1000, Train Loss: 0.00000058, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 665/1000, Train Loss: 0.00000058, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 666/1000, Train Loss: 0.00000057, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 667/1000, Train Loss: 0.00000056, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 668/1000, Train Loss: 0.00000056, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 669/1000, Train Loss: 0.00000056, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 670/1000, Train Loss: 0.00000055, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 671/1000, Train Loss: 0.00000054, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 672/1000, Train Loss: 0.00000054, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 673/1000, Train Loss: 0.00000054, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 674/1000, Train Loss: 0.00000053, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 675/1000, Train Loss: 0.00000053, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 676/1000, Train Loss: 0.00000053, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 677/1000, Train Loss: 0.00000053, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 678/1000, Train Loss: 0.00000051, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 679/1000, Train Loss: 0.00000051, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 680/1000, Train Loss: 0.00000051, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 681/1000, Train Loss: 0.00000050, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 682/1000, Train Loss: 0.00000050, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 683/1000, Train Loss: 0.00000050, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 684/1000, Train Loss: 0.00000049, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 685/1000, Train Loss: 0.00000048, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 686/1000, Train Loss: 0.00000048, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 687/1000, Train Loss: 0.00000048, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 688/1000, Train Loss: 0.00000047, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 689/1000, Train Loss: 0.00000045, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 690/1000, Train Loss: 0.00000045, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 691/1000, Train Loss: 0.00000045, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 692/1000, Train Loss: 0.00000045, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 693/1000, Train Loss: 0.00000044, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Epoch 694/1000, Train Loss: 0.00000044, Validation Loss: 0.00000006, Accuracy: 1.0000\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 訓練模型\n",
    "# 訓練設置\n",
    "num_epochs = 1000\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = float('inf')\n",
    "best_accuracy = 0.0\n",
    "patience = 50\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0.0\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    # 訓練模式\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.float()  # Ensure labels match outputs shape\n",
    "        #print(outputs,labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()  # 累加每個 batch 的損失值\n",
    "\n",
    "    epoch_train_loss = total_train_loss / len(train_loader)  # 計算每個 epoch 的平均訓練損失值\n",
    "    loss_values.append(epoch_train_loss)  # 將平均訓練損失值添加到列表中\n",
    "\n",
    "    # 驗證模式\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.float() # Ensure labels match outputs shape\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()  # 累加每個 batch 的損失值\n",
    "            val_predictions.append(outputs)\n",
    "            val_labels.append(labels)\n",
    "    epoch_val_loss = total_val_loss / len(valid_loader)  # 計算每個 epoch 的平均驗證損失值\n",
    "    val_loss_values.append(epoch_val_loss)  # 將平均驗證損失值添加到列表中\n",
    "\n",
    "    # 計算 accuracy（根據需要調整）\n",
    "    #accuracy = mean_squared_error(val_labels, val_predictions)\n",
    "    # Convert lists to tensors\n",
    "    val_predictions = torch.cat(val_predictions)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    \n",
    "    # Convert logits to probabilities and round to get binary predictions\n",
    "    val_predictions_rounded = torch.round(torch.sigmoid(val_predictions))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(val_labels.cpu().numpy(), val_predictions_rounded.cpu().numpy())\n",
    "\n",
    "\n",
    "    # 儲存最佳模型\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print('model saved.') \n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.8f}, Validation Loss: {epoch_val_loss:.8f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # 提早停止\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測準確率： 1.0\n",
      "混淆矩陣:\n",
      "[[0 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "# 將模型設為評估模式\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 預測\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test_tensor)\n",
    "\n",
    "#print(predictions)\n",
    "# 取得預測的類別\n",
    "predicted_classes = torch.argmax(predictions, dim=1)\n",
    "#print(predicted_classes)\n",
    "predicted_classes = predicted_classes.numpy()\n",
    "y_test = np.array(y_test)\n",
    "#print(y_test)\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(\"預測準確率：\", accuracy)\n",
    "\n",
    "# 輸出預測結果\n",
    "#print(predicted_classes)\n",
    "\n",
    "# 計算混淆矩陣\n",
    "cm = confusion_matrix(y_test, predicted_classes, labels=[0, 1])\n",
    "# 將混淆矩陣轉換成百分比\n",
    "#cm_percentage = cm / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "print(\"混淆矩陣:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 7])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "news_data=clean_data[-10:]\n",
    "\n",
    "\n",
    "# 去除字符串列名，并将剩余数值转换为 tensor\n",
    "news_data_values = news_data.values\n",
    "news_data_tensor = torch.tensor(news_data_values, dtype=torch.float32)\n",
    "\n",
    "print(news_data_tensor.shape)\n",
    "#news_data_tensor = torch.stack(news_data_tensors)\n",
    "news_data_tensor = news_data_tensor.unsqueeze(0).repeat(2, 1, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    results = model(news_data_tensor)\n",
    "    \n",
    "results_classes = torch.argmax(results, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可以進場，10個交易日後會賺。\n"
     ]
    }
   ],
   "source": [
    "if results_classes[0]==1:\n",
    "    msg='可以進場，10個交易日後會賺。'\n",
    "else:\n",
    "    msg='不要進場。'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_message(msg, image_path):\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer uTRd8WZAkORjjq5AYTwWqSCx7MuKMrzX9N9FiqkehsX'\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        'message': msg\n",
    "    }\n",
    "    files = {\n",
    "        'imageFile': open(image_path, 'rb')\n",
    "    }\n",
    "\n",
    "    r = requests.post(\"https://notify-api.line.me/api/notify\", headers=headers, data=payload, files=files)\n",
    "    return r.status_code, r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "狀態碼: 200\n"
     ]
    }
   ],
   "source": [
    "# 訊息和圖片路徑\n",
    "#msg = 'test'\n",
    "imgfile = r'C:/Users/Dominic/Desktop/小說集/家裡蹲妹妹竟然要當冒險者/03447-3233128412-blue cloak.png'\n",
    "\n",
    "status_code, response_data = send_message(msg, imgfile)\n",
    "print(f\"狀態碼: {status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
